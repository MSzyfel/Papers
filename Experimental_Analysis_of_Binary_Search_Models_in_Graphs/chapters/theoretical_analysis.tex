\chapter{Theorethical Analysis}

The following chapter is concerned with the presentation and theoretical analysis of the algorithms for the Search Problem. We partition the analysis into 5 main sections: Paths, Unitary costs in trees, Non-uniform costs in trees, Arbitrary graphs and Miscellaneous. The variants are grouped according to the similarity of structure, hardness and the techniques used to solve them. It should be noted that however this choice is arbitrary as sometimes distant versions of the problem remain connected and some techniques used to solve one version might be somewhat useful in the other.
\section{Paths}
In general, all of the variants of the problem dealing with paths are known to be solvable in polynomial time. This is due to the fact that the number of subpaths of a path is of size $\binom{n}{2}=O\br{n^2}$. Such property allows us to construct efficient dynamic programming solutions, which when naively implemented, usually run in time $O\br{n^3}$. The key part of the analysis is often to show how to optimize such solution in order to reduce the factor of $O\br{n}$ thus obtaining $O\br{n^2}$ running time.
Let $V\br{P}=v_1,\dots,v_n$. In the following considerations by  $\OPT_{sum}\br{i,j}$ we will denote the cost of optimal decision tree for a subpath $v_i,..,v_j$ according to the average case cost and similarly by $\OPT_{max}\br{i,j}$ we will denote the cost of optimal decision tree for a subpath $v_i,..,v_j$ according to the worst case cost. Whenever clear from the context we will drop the subscript and simply write $\OPT\br{i,j}$. For both variants we have that $\OPT=\OPT\br{1,n}$. By a slight abuse of notation we will also use $\OPT\br{i,j}$ to denote the root query of the decision tree whose cost is equal to this value.
In this section we will be only concerned with the edge query model, as each of the constructed solutions can be easily altered to solve the vertex query version of the problem. The following paragraph introduces us with the general recurrence relationships exploited in the dynamic programming. 
\paragraph{A warm up: $O\br{n^3}$ algorithm for $P||E,c|| \COST_{max}$ and $P||E,c, w|| \sum C_i$}

First of all, following the definition of $\OPT\br{i,j}$ we get that $\OPT\br{i,i}=0$ for both worst and average case criteria.
Fix some $i<j$. The two next recurrence relationships stem from a fact that  there must exist some query among edges of $v_i,..v_j$ which is the root of the optimal decision tree. Define $D_{max}$ to be this decision tree (for the worst case cost) and $q_{max}=r\br{D_{max}}$ to be its root query. Let $P_1,P_2\in P-q_{max}$ and let $D_1, D_2\in D-q_{max}$ be the subtrees of $D_{max}$ being decision trees for $P_1$ and $P_2$ accordingly. Let $D_{max}'$ be the costiest of the two and $P_{max}'$ be the according path. We have that: $\OPT_{max}\br{i,j}=\COST_{max}\br{D_{max}}=c\br{q_{max}}+\COST_{max}\br{D_{max}'}$. 
By the optimality of $\OPT_{max}\br{i,j}$ we immediately obtain that $D_{max}'$ is the optimal decision tree for $P_{max}'$. This results in the following recurrence relationship:
$$
\OPT_{max}\br{i,j} = \min_{i\leq k<j}\brc{c\br{v_kv_{k+1}}+\max\brc{\OPT_{max}\br{i, k}, \OPT_{max}\br{k+1, j}}}
$$
Similarly, fix again $i<j$ and define $D_{sum}$ to be the optimal decision tree (for the average case cost) for $v_i,\dots,v_j$ and $q_{sum}=r\br{D_{sum}}$ to be its root query. Let $P_1,P_2\in P-q_{sum}$ and $D_1, D_2\in D-q_{sum}$ be the subtrees of $D_{sum}$ begin decision trees for $P_1$ and $P_2$ accordingly. Let $C\br{D_{sum}, x}$ denote the cost of finding $x\in\brc{v_i,\dots,v_j}$ using $D_{sum}$. Let $w\br{i,j}=\sum_{i\leq k\leq j}w\br{v_k}$. We have that:
$$
\OPT_{sum}\br{i,j}=\sum_{x\in v_i,\dots,v_j}w\br{x}\cdot \COST_{sum}\br{D_{sum}, x}=w\br{i,j}\cdot c\br{q_{sum}} + \COST_{sum}\br{D_1} + \COST_{sum}\br{D_2}
$$
By the optimality of $\OPT_{max}\br{i,j}$ we immediately obtain that $D_1$ is the optimal decision tree for $P_1$ and $D_2$ is the optimal decision tree for $P_2$. This results in the following recurrence relationship:
$$
\OPT_{sum}\br{i,j} = \min_{i\leq k<j}\brc{w\br{i,j}\cdot c\br{v_kv_{k+1}}+\OPT_{sum}\br{i, k}+ \OPT_{sum}\br{k+1, j}}
$$

Both recurrences can be solved using dynamic programming in time $O\br{n^3}$. To see this, recall that there are at most $\binom{n}{2}$ values for all possible choices of values of $i$ and $j$ and each of them requires checking at most $n-1$ choices for the root of the optimal decision tree.

Despite being polynomial, $O\br{n^3}$ is substantial amount of calculation for the practical purposes we are interested in. In subsequent considerations we show how, using clever tricks, lower down the running time of these dynamic programming algorithms in some special cases. 
\subsection{Average case, non-uniform weights}
\begin{theorem}
    There exists an $O\br{n^2}$ algorithm for $P||E, w|\sum C_i$
    \begin{proof}
        
The idea behind the speed-up described below is due to Knuth \cite{Knuth1973} and \cite{EffDPusingQI}. For every $i\leq k< j$ let $\OPT_k\br{i,j} = w\br{i,j} + \OPT\br{i, k} + \OPT\br{k, j}$ be the optimal cost of searching in $v_i,\dots,v_j$ assuming that the edge $v_kv_{k+1}$ is the root of the decision tree. We have that $\OPT\br{i,j}\leq \OPT_k\br{i,j}$. Additionally, define 
$K\br{i,j} = \max_{i\leq k< j}\brc{k|\OPT_k\br{i,j}=\OPT\br{i,j}}$ to be the largest index such that setting $v_kv_{k+1}$ as the root of the decision tree yields the optimal solution. 

Let $i \leq i' \leq j \leq j'$.
Observe that the weight function fulfills the following inequalities:
\begin{enumerate}
\item Monotocity: $w\br{i',j}\leq w\br{i,j'}$
\item The quadrangle inequality (QI):
$
w\br{i,j} + w\br{i',j'}\leq 
w\br{i',j} + w\br{i,j'}
$
\end{enumerate}
Using the above fact we will firstly show the following:
\begin{lemma}
   The $\OPT$ function satisfies the quadrangle inequality
   \begin{proof}
       Let $i \leq i' \leq j \leq j'$. The proof is by induction on $l=j'-i$. Assume by induction that:
       $$\OPT\br{i,j} + \OPT\br{i',j'}\leq 
\OPT\br{i',j} + \OPT\br{i,j'}$$
Whenever $i=i'$ or $j=j'$ the claim follows trivially and therefore is true for $j\leq 1$ so assume otherwise. There are two cases:
\begin{enumerate}
   \item $i'=j$.
   Let $k=K\br{i,j'}$. In this case the inequality reduces to $\OPT\br{i,j} + \OPT\br{j,j'}\leq \OPT\br{i,j'}$. There are two subcases:
   \begin{enumerate}
       \item $k\leq j$.
       We have that:
       \begin{align*}
       \OPT\br{i, j} + \OPT\br{j, j'} &\leq \OPT_k\br{i, j} + \OPT\br{j, j'} 
       \\ 
       &= 
       w\br{i, j} + \OPT\br{i, k} + \OPT\br{k+1, j} + \OPT\br{j, j'}
       \\ 
       &\leq
       w\br{i, j'} + \OPT\br{i, k} + \OPT\br{k+1, j'} 
       \\
       &=
       \OPT_k\br{i, j'} \\
       &= \OPT\br{i, j'}
       \end{align*}
       Where the first inequality and the first equality are due to the definition of $\OPT_k$, the second inequality is due to monotonicity of $w$ and the induction hypothesis and the last two equalities are again due to the definition of $\OPT_k$.
        \item The case when $k\geq j$ is symmetrical.
   \end{enumerate}
    \item $i' < j$.
    Let $y=K\br{i',j}$ and $z=K\br{i,j'}$. There are again two symmetric cases:
    \begin{enumerate}
        \item $z\leq y$. We have that:
        \begin{align*}
        &\OPT\br{i, j} + \OPT\br{i', j'} \\
        &\leq \OPT_z\br{i, j} + \OPT_y\br{i', j'} \\
        &=w\br{i, j} + w\br{i', j'} + \OPT\br{i, z} + \OPT_z\br{z+1, j} + \OPT_y\br{i', y} + \OPT_y\br{y+1, j'} \\
        &\leq w\br{i', j} + w\br{i, j'} + \OPT\br{i, z} + \OPT_y\br{i', y} + \OPT_z\br{y+1, j} + \OPT_y\br{z+1, j'}\\
        &= \OPT_y\br{i', j} + \OPT_z\br{i, j'} \\
        &= \OPT\br{i', j} + \OPT\br{i, j'}
        \end{align*}
        Where the first inequality and the first equality are due to the definition of $\OPT_k$, the second inequality is due to QI of $w$ and the induction hypothesis at $z\leq y<j < j'$ and the last two equalities are again due to the definition of $\OPT_k$.
        \item Also this time the other case when $k\geq j$ is symmetrical.
    \end{enumerate}
\end{enumerate} 
   \end{proof}
\end{lemma} 
Having the above lemma we will now prove the following:
\begin{lemma}
   $K\br{i,j-1}\leq K\br{i,j}\leq K\br{i +1,j}$
   \begin{proof}
   To prove the first inequality $K\br{i,j-1}\leq K\br{i,j}$ we will show that for $i\leq k \leq k' < j$ we have that: $\OPT_{k'}\br{i, j - 1} \leq \OPT_{k}\br{i, j - 1}$ implies that $\OPT_{k'}\br{i, j} \leq \OPT_{k}\br{i, j}$. This condition suffices as whenever $k'=K\br{i, j - 1}$ this means that either $k'=k$ or $k\neq K\br{i, j}$ as choosing $v_{k'}v_{k'+1}$ as the root of the decision tree provides a solution which cannot be worse\footnote{Note that by the definition we require $K\br{i, j}$ to be maximal.}. By using QI at $k\leq k'\leq j -1< j$ we have:
   $$
   \OPT\br{k, j-1} + \OPT\br{k', j}\leq \OPT\br{k', j-1} + \OPT\br{k, j}
   $$
   By adding $w\br{i,j-1}+w\br{i,j}+\OPT\br{i, k}+\OPT\br{i, k'}$ to both sides we obtain:
   $$
   \OPT_k\br{i, j-1} + \OPT_{k'}\br{i, j-1} \leq \OPT_{k'}\br{i, j-1} + \OPT_{k}\br{i, j-1}
   $$
   Which implies the claim. 
   The second inequality $K\br{i,j}\leq K\br{i +1,j}$ follows similarly from the QI at $i < i+1 \leq k \leq k' $.
   \end{proof}
\end{lemma}
 
The above lemma allows us to the amount of computation required. The idea is as follows: Before calculating $\OPT\br{i,j}$ we firstly calculate the values of $\OPT\br{i -1,j}$ and $\OPT\br{i,j + 1}$. In doing so we also calculate the indices $K\br{i,j-1}$ and $K\br{i +1,j}$ required to narrow the space of possible choices for value of $K\br{i,j}$. We obtain the following recurrence relationship:
$$
\OPT_{sum}\br{i,j} = \min_{K\br{i,j-1}\leq k\leq K\br{i +1,j}}\brc{w\br{i,j}+\OPT_{sum}\br{i, k}+ \OPT_{sum}\br{k+1, j}}
$$
It remains to show that the running time can be bounded by $O\br{n^2}$. The amount of computation steps required by the algorithm is equal to:
\begin{align*}
\sum_{i=1}^n\sum_{j=i+1}^n\br{K\br{i + 1, j} - K\br{i,j - 1}} &= \sum_{i=1}^n\sum_{j=i}^n\br{K\br{i + 1,j+1} - K\br{i,j}}
\\
&=\sum_{i=1}^n\br{K\br{i + 1,n}-K\br{1,i}} = O\br{n^2}
\end{align*}
Where the second equality is due to the fact that all of the terms except $K\br{i + 1,n}$ and $K\br{1,i}$ cancel, and the last equality is trivially due to the fact that $K\br{i + 1,n} < n$. This proves the claim.
    \end{proof}
\end{theorem}
\subsection{Non-uniform costs, worst case}
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
\subsection{Non-uniform costs, Average case, uniform weights}
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
\section{Unitary costs, trees}
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
\subsection{Worst case}
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
\subsection{Average case, non-uniform weights}
The problem of average case searching is also solvable in polynomial time assuming all of the weight are uniform. However the procedure is the same as for the weighted case and only the running time differ. Hence we combine these results in one section. Note that it is yet unknown whether the same holds for the weighted version of the problem and the fastest known algorithm runs in pseudopolynomial time. Using this one may also obtain a FPTAS using a standard rounding trick. Before that, however we show that a simple greedy heuristics achieves a 2-approximation for $T|V,w|\sum C_j$.
\paragraph{A warm up: greedy achieves 2-approximation for $T|V,w|\sum C_j$}
The weight centroid is a vertex $c\in T$ such that for every $H\in T-c$ we have that $w\br{h}\leq \frac{w\br{T}}{2}$. The existence of the (unweighted) centroid has been known since 19th century \cite{Jordan1869}. The proof of the existence of the weight centroid i straightforward and can be summarized as follows: pick any vertex $v\in T$ and if its not a weight centroid move to the neighbor $v'$ of $v$ such that the $H\in T-v$ such that $v'\in H$ has weight $w\br{H}>\frac{w\br{T}}{2}$. It is easily observable that the algorithm always succeeds and visits each vertex at most once. The greedy algorithm is as follows: pick the centroid $c$ of $T$ as the root of the decision tree for $T$ and proceed recursively in $T-c$. The following analysis of greedy is due to \cite{Fast_app_centroid_trees}.

\begin{theorem}
    Let $D_c$ be the cost of the greedy solution. Then $\COST_{D_c}\br{T}\leq 2\OPT\br{T}-w\br{T}$.
    \begin{proof}
        We start with the following lemma:
        \begin{lemma}\label{lemma:avg_lb_centroid}
            Let $D$ be any decision tree for $T$ and let $c$ be the centroid of $T$. Then:
            $$
            \OPT\br{T}\geq \frac{w\br{T}}{2}+\frac{w\br{c}}{2}+\sum_{H\in T-c}\OPT\br{H}
            $$
            \begin{proof}
                Let $r=r\br{D}$. There are two cases:
                \begin{enumerate}
                    \item $r=c$. In such case the cost of the solution is trivially lower bounded by:
                    $$
                    \COST_{D}\br{T}\geq w\br{T}+\sum_{H\in T-r}\OPT\br{H}\geq \frac{w\br{T}}{2}+\frac{w\br{c}}{2}+\sum_{H\in T-c}\OPT\br{H}
                    $$
                    \item $r\neq c$. In such case denote by $H_r$ the connected component of $T-c$ such that $r\in H_r$. We have that the contribution of each $v\in H_r$ is at least $\spr{Q_{D|H_r}\br{v}}$ so the overall contribution of vertices in $H_r$ is at least $\COST_{D|H_r}\br{H_r}$. For every $H\in T-c$ such that $H\neq H_r$ and $v\in H$ we have that $\brc{r}\cup Q_{D|H}\br{v}\subseteq Q_{D}\br{v}$ so we have that the contribution of vertices in $H$ is at least $w\br{H}+\COST_{D|H}\br{H}$. Additionally the contribution of $c$ is at least $w\br{c}$ since query to $r$ precedes the query to $c$. We have that:
                    \begin{align*}
                        \COST_D\br{T}&\geq 2w\br{c}+\COST_{D|H_r}\br{H_r}+\sum_{H\in T-c, H\neq H_r}\br{w\br{H}+w\br{c}+\COST_{D|H}\br{H}}\\
                        &\geq w\br{T}-w\br{H_r}+\sum_{H\in T-c}\OPT_{D|H}\br{H}\\
                        &\geq \frac{w\br{T}}{2}+w\br{c}+\sum_{H\in T-c}\OPT_{D|H}\br{H}
                    \end{align*}
                    where in the last inequality we used the fact that $c$ is a centroid of $T$.
                \end{enumerate}
            \end{proof}
        \end{lemma}
        The proof is by induction on the size of $T$. When $n\br{T}=1$ we have that $\COST_{D_c}\br{T}=w\br{T}=2\OPT\br{T}-w\br{T}$. Assume therefore that $n\br{T}>1$ and let $c$ be the centroid of $T$. We have that:
        \begin{align*}
            \COST_{D_c}\br{T} &= w\br{T}+\sum_{H\in T-c}\COST_{D_c|H}\br{H}\\
            &\leq w\br{T}+\sum_{H\in T-c}\br{2\cdot\OPT\br{H}-w\br{H}}\\
            &= w\br{c}+\sum_{H\in T-c}2\cdot\OPT\br{H}\\\
            &\leq 2\OPT\br{T}-w\br{T}
        \end{align*}
        where the first inequality is by the induction hypothesis and the second inequality is by the Lemma \ref{lemma:avg_lb_centroid}.
    \end{proof}
\end{theorem}
\begin{theorem}
    The greedy decision tree can be found in $O\br{n\log n}$ running time.
    \begin{proof}
        We use the data structure called \textit{top trees}. The top trees are used to maintain dynamic forests under
insertion and deletion of edges. The following theorem is due to \cite{toptrees}:
    \begin{theorem}
        We can maintain a forest with positive vertex weights on n vertices
under the following operations:
\begin{enumerate}
    \item Add an edge between two given vertices $u$, $v$ that are not in the same connected component.
    \item Remove an existing edge.
    \item Change the weight of a vertex.
    \item Retrieve a pointer to the tree containing a given vertex.
    \item Find the centroid of a given tree in the forest.
\end{enumerate}
Each operation requires $O\br{\log n}$ time. A forest without edges and with n arbitrarily weighted vertices can be
initialized in $O\br{n}$ time.
    \end{theorem}
        We begin with building the top tree out of $T$. We begin with empty top tree and add each edge one by one. Then we find the centroid of $T$ and remove each edge incident to it. Then we recurse on this new created tree (excluding the subtree consisting of $c$). Since the algorithm finds each vertex once and removes each edge once the total running time is of order $O\br{n\log n}$.
    \end{proof}
\end{theorem}
\paragraph{PTAS for $T|V,w|\sum C_j$}
\paragraph{FPTAS for $T|V,w|\sum C_j$}
As it turns out one may employ a different dynamic programming technqieu to obtain an FPTAS for $T|V,w|\sum C_j$. To do so, we firstly design a pseudopolynomial time procedure which then combine with a standard rounding scheme. To do so, we begin with the following bound due to \cite{Fast_app_centroid_trees} (we managed to simplify the proof a bit):
\begin{theorem}
    Let $D^*$ be the optimal decision tree for $T|V,w|\sum C_j$. Then we have:
    $$\COST_{max, D^*}\br{T}\leq \cl{\log_{3/2}w\br{T}}$$
    \begin{proof}
        For the sake of the argument we define the following operation. Let $D$ be a decision tree for some tree $T$ and $v\in V\br{T}$. We define $D_v$ to be a decision tree such that $r\br{D}=v$. Additionally, for each $H\in T-v$ we hang $D_{|H}$ below $v$ in $D$. This operation is called a \textit{lifting} of a vertex. Let $x,v\in V\br{T}$ and $H_x\in T-v$ such that $x\in H_x$ if $x\neq v$. We have:
        $$
        Q_{D^v}\br{x}=\begin{cases}
            \brc{v} \text{if } x=v\\
            \brc{v}\cap \br{Q_{D}\br{x}\cup V\br{H}} \text{otherwise }
        \end{cases}
        $$
        We will show that after each query the size of the candidate subset decreases by a factor of $2/3$. To do so, assume contrary. Let $D$ be a minimum height decision tree for which this is not the case. By doing so we can assume that $r=r\br{D}$ has a child $c$ such that $w\br{D_y}> \frac{2w\br{T}}{3}$. Let $H_r$ denote the set of vertices not in the same component of $T-r$ as $c$ and $H_c$ denote the set of vertices not in the same component of $T-c$ as $r$. We also define $H_{r, c}=V\br{T}-H_r-H_c$. By the assumption $w\br{H_c\cup H_{r, c}}>\frac{2w\br{T}}{3}$ and $w\br{H_r}<\frac{w\br{T}}{3}$. There are two cases:
        \begin{enumerate}
            \item $w\br{H_c}>\frac{w\br{T}}{3}$. In such case we augment $D$ by lifting $c$. The query sequences of vertices in $H_c$ decrease by one query, the
query sequences of vertices in $H_r$ increase by one and query sequences of vertices in $H_{r,c}$ remain unchanged. We have:
$$
\COST_{avg, D^v}\br{T}-\COST_{avg, D}\br{T}=w\br{H_r}-w\br{H_c}< 0
$$
thus, a contradiction.
\item $w\br{H_c}\leq \frac{w\br{T}}{3}$. We have that $w\br{H_{r, c}}$ and additionally $H_{r, c}\neq\emptyset$. Let $s\in P\br{r, c}$. In such case we augment $D$ by lifting $s$. The query sequences of vertices in
$H_{c}$ remain  unchanged, since these vertices gain $t$ and lose $r$ as ancestors. The query sequences of vertices in $H_{r,c}$ are
decreased by at least one query, since each loses at least one ancestor from ${c, r}$. The query sequences of
vertices in $H_r$ increase by one, since each of these vertices gains $t$ as ancestor. We have:
$$
\COST_{avg, D^v}\br{T}-\COST_{avg, D}\br{T}=w\br{H_r}-w\br{H_{r,c}}< 0
$$
again, a contradiction.
        \end{enumerate}
As after each query to size of the candidate subset shrinks by the ratio of $2/3$ the claim follows.
    \end{proof}
\end{theorem}
The above bound on the cost allows us to assume that the height of the optimal decision tree is of order of $O\br{l\log w\br{T}}$. We will exploit the fact to build a btoom-up dynamic programming algorithm which for every $v\in V\br{T}$ will enumerate all possible "shapes" of the query sequence toward $v$. As to place the query to $v$ we only need an information about which spots in this query sequences are free and which are not, at most $2^{O\br{\log w\br{T}}}=\text{poly}\br{W}$ options need to be checked. 
\section{Non-uniform costs, trees}
In this section we will be only concerned with the vertex-query variant of the problem. This is due to the fact that the edge variant is easily reducible to the vertex variant of the problem and this reduction preserves the approximation ratio (note that this reduces the problem to the version in which the last query may be omitted but all of the algorithms can be easily altered to consider this assumption). This is done by subdividing each edge $e$ with a new vertex $v_e$ of cost $c\br{v_e}=c\br{e}$. If we consider the average case criterion then we additionally set $w\br{v_e}=0$. It is immediate that the optimal decision tree for the this vertex query model instance can be used to obtain a decision tree for the original instance. To do so, simply replace each query to vertex $v_e$ with the query corresponding to $e$. 

\subsection{Worst case}

The problem for non-uniform is NP-hard even when restricted to spiders of diameter $6$ and binary trees.
A simple greedy heuristics which always queries the middle vertex of the graph achieves a $O\br{\log n}$-approximation \cite{Dereniowski2009ERankOfWTs}. However one can obtain better results. 
We begin with the following simple lemma which will become useful in few arguments:
\begin{lemma}\label{lemma:subtreeCost}
    Let $T'$ be a connected subtree of $T$. Then, $\OPT\br{T'}\leq\OPT\br{T}$.
\end{lemma}
The proof of this fact is trivial and will be left as an exercise for the reader.
\paragraph{A warm up: $O\br{\log n/\log\log n}$-approximation algorithm  for $T||V,c||C_{max}$}
This first algorithm is an adapted and simplified version of the algorithm due to \cite{Cicalese2016OnTSPwNonUniCost} for the edge query model.
\begin{theorem}
    There exists a polynomial time, $O\br{\log n/\log\log n}$-approximation algorithm for the $T||V,c||C_{max}$ problem .
    \begin{proof}
        
To construct a decision tree we will use the following exact procedure:
\begin{lemma}
    There exists a $O\br{2^nn}$ algorithm for $T||V,c||C_{max}$
    \begin{proof}
        The algorithm is a general version of the dynamic programming procedure for paths. We have that:
        $$
        \OPT_{max}\br{T} = \min_{v\in V\br{T}}\brc{c\br{v}+\max_{H\in T-v}\brc{\OPT_{max}\br{H}}}
        $$
        There are there are at most $O\br{2^n}$ different subtrees of $T$ to be checked. Additionally, and for each $v\in V\br{T}$ there are at most $\deg_T\br{v}$ possible responses to check in the inner $\max$ function. Therefore for each subproblem there are at most
        $
        \sum_{v\in V\br{T}}\deg_T\br{v} = 2m = 2n-2
        $
        comparison operations to be performed. As at each level of the recursion the algorithm considers all possible choices of the next queried vertex $v$ it returns the optimal decision tree for $T$ and the claim follows.
    \end{proof}
\end{lemma}
\begin{observation}\label{neighborsPathObservation}
    Let $D$ be a partial decision tree for tree $T$. Let $T'$ be a subtree of $T$. Let $Q$ be a set of all queries to vertices from $N_{T}\br{V\br{T'}}$ in $D$ such that every for every $q\in Q$: $q$ is queried before every vertex in $T'$. Then $D\angl{Q}$ is a path. 
    \begin{proof}
        Let $x\in N_{T}\br{V\br{T'}}$. In such case, for every vertex $v\in V\br{T-V\br{T'}-N_{T}\br{V\br{T'}}}$ the answer to a query to $v$ is always towards the same $u\in N_{T}\br{v}$, so until a vertex from $T'$ is queried, no query $q$ can partition vertices from $N_{T}\br{V\br{T'}}$ into disjoint subtrees of candidate vertices except when $q\in N_{T}\br{V\br{T'}}$. After a query to $q$, the only different response is when $x=q$, in which case no further queries are needed, so queries in $Q$ must belong to a path in $D$.
    \end{proof}
\end{observation}



Let $k=2^{\fl{\log\log n}+2}$.
The basic idea is as follows. The algorithm is recursive. Let $\mathcal{T}$ be the tree currently processed by the algorithm. If $n\br{T}\leq k$ then we use the exponential time algorithm to find the optimal solution in time $2^kk=\text{poly}\br{n}$.

If otherwise, to build a solution (see Algorithm \ref{cicaleseInspired}) we will firstly define a set $\mathcal{X}\subseteq V\br{\mathcal{T}}$ which will be of size at most $k$. We build $\mathcal{X}$ iteratively. Starting with an empty set we pick the centroid $x_1$ of $T$ which we add to $\mathcal{X}$. Then we take the forest $F=T-x$, find the largest $H\in F$, pick its centroid $x_2$ and append it to $\mathcal{X}$. We continue this in $F-H + \br{H-x_2}$ until $\spr{\mathcal{X}}=k$.
\begin{lemma}\label{lemma:componentSize}
    For every $H\in \mathcal{T}-\mathcal{X}$ we have that $n\br{H}\leq n\br{\mathcal{T}}/\log\br{n}$.
    \begin{proof}
        We prove by induction on $t$ that deleting first $2^t$ centroids from $T$ each connected components $H_t$ has size at most $n\br{H_t}\leq n\br{\mathcal{T}}/2^{t-1}$. For the case when $t=0$ we have that after 1 iteration every $H_1$ has size at most $n\br{T}/2\leq 2\br{n}$ so the base of induction is complete.

        Fix $t>0$ and by assume by the induction hypothesis that after $2^{t-1}$ iterations all
    \end{proof}
\end{lemma}

We also define set $\mathcal{Y}\subseteq V\br{\mathcal{T}}$ which consists of vertices in $\mathcal{X}$ and all vertices in $v\in \mathcal{T}\angl{X}$ such that $\deg_{T\angl{\mathcal{X}}}\br{v}\geq 3$.
Furthermore, we define set $\mathcal{Z}\subseteq V\br{\mathcal{T}}$ as a set consisting of vertices in $\mathcal{Y}$ and for every $u,v\in \mathcal{Y}$ such that $\mathcal{P}_{\mathcal{T}}\br{u, v}\neq\emptyset$ and $\mathcal{P}_{\mathcal{T}}\br{u, v}\cap \mathcal{Y}=\emptyset$ we add to $\mathcal{Z}$ the vertex $\argmin_{z\in \mathcal{P}_{\mathcal{T}}\br{u, v}}\brc{c\br{z}}$ (for example see Figure \ref{exampleTreeWithSetZ}). We then create an auxiliary tree $\mathcal{T}_{\mathcal{Z}}=\br{\mathcal{Z},\brc{uv|\mathcal{P}_{\mathcal{T}}\br{u, v}\cap \mathcal{Z}=\emptyset}}$ (for example see Figure \ref{exampleAuxTreeTZ}). The algorithm builds an optimal decision tree $D_{\mathcal{Z}}$ for $\mathcal{T}_{\mathcal{Z}}$ by applying the exponential time algorithm. Observe, that  $D_{\mathcal{Z}}$ is a  partial decision tree for $\mathcal{T}$, so we get that:
\begin{observation}\label{observation:CostDZinT}
    $\COST_{D_{\mathcal{Z}}}\br{\mathcal{T}_{\mathcal{Z}}}=\COST_{D_{\mathcal{Z}}}\br{\mathcal{T}}$.
\end{observation}
Then for each $H\in \mathcal{T}-\mathcal{Z}$ we recursively apply the same algorithm to obtain the decision tree $D_H$ and we hang it in $D_\mathcal{Z}$ below the unique last query to vertex in $N_{\mathcal{T}'}\br{H}$ (By Observation \ref{neighborsPathObservation}).
\input{pseudocodes/cicalese_inspired}

\begin{lemma}\label{lemma:auxTreeSize}
    Let $\mathcal{T}_{\mathcal{Z}}$ be the auxiliary tree. Then, $\spr{V\br{\mathcal{T}_{\mathcal{Z}}}}\leq 4k-3$.
    \begin{proof}
        We firstly show that $\spr{\mathcal{Y}}\leq 2k-1$. We use induction of the centroids in $\mathcal{X}$. For $1\leq i\leq k$ let $x_i$ denote the $i$-th centroid added to $\mathcal{X}$. We will construct a family of sets $\mathcal{X}_1, \mathcal{X}_2,\dots, \mathcal{X}_{\spr{\mathcal{H}}}$ such that for any $1\leq t\leq \spr{\mathcal{X}}$: $\spr{\mathcal{X}_t}=t$ and $\mathcal{X}_{\spr{\mathcal{X}}}=\mathcal{X}$. For each $\mathcal{X}_t$ we will also construct a corresponding set $\mathcal{Y}_t$, ensuring $\mathcal{Y}_{\spr{\mathcal{X}}}=\mathcal{Y}$. We will build the sets $\mathcal{Y}_{t}$ to ensure that $\spr{\mathcal{Y}_t}\leq 2t-1$. 
        
        Let $\mathcal{X}_1=\brc{x_1}$, $\mathcal{Y}_1=\brc{x_1}$. This establishes the base case. Assume by induction on $t\geq1$ that $\spr{\mathcal{Y}_t}\leq 2t-1$ for some $t>1$. Let $\mathcal{X}_{t+1} =\mathcal{X}_{t}\cup \brc{x_{t+1}}$ and let $\mathcal{T}_t=\mathcal{T}\angl{\mathcal{X}_{t}}$ If $x_t\in V\br{\mathcal{T}_t}$ then $\mathcal{Y}_{t+1}=\mathcal{Y}_{t}\cup \brc{x_t}$. If otherwise let $y_t \in V\br{\mathcal{T}_t}$ be the unique vertex such that $P\br{x_t, y_t}\cap V\br{\mathcal{T}_t}=\emptyset$. Then $\mathcal{Y}_{t+1}=\mathcal{Y}_{t}\cup \brc{x_t, y_t}$. As by induction $\spr{\mathcal{Y}_{t}}\leq 2t-1$ and we add at most two vertices to it to obtain $\mathcal{Y}_{t+1}$ the induction step is complete.
        
        As paths between vertices in $\mathcal{Y}$ form a tree, at most $2k-2$ additional vertices are added to $\mathcal{Y}$ while constructing $\mathcal{Z}$ (at most one for each path) and the lemma follows.
    \end{proof}
\end{lemma}
\begin{lemma}\label{lemma:auxTreeCost}
    Let $\mathcal{T}_{\mathcal{Z}}$ be the auxiliary tree. Then, $\OPT\br{\mathcal{T}_{\mathcal{Z}}}\leq \OPT\br{\mathcal{T}}$.
    \begin{proof}
        Let $D^*$ be the optimal strategy for $\mathcal{T}\angl{\mathcal{Z}}$. We build a new decision tree $D_{\mathcal{Z}}'$ for $\mathcal{T}_{\mathcal{Z}}$ by transforming $D^*$: Let $u,v\in \mathcal{Y}$ such that $\mathcal{P}_{\mathcal{T}}\br{u, v}\neq\emptyset$ and $\mathcal{P}_{\mathcal{T}}\br{u, v}\cap \mathcal{Y}=\emptyset$. Let $q\in V\br{D^*}$ such that $q\in \mathcal{P}_{\mathcal{T}}\br{u, v}$ is the first query among vertices of $\mathcal{P}_{\mathcal{T}}\br{u, v}$. We replace $q$ in $D^*$ by the query to the distinct vertex $v_{u,v}\in \mathcal{P}_{\mathcal{T}}\br{u, v}\cap \mathcal{Z}$ and delete all queries to vertices $\mathcal{P}_{\mathcal{T}}\br{u, v}-v_{u,v}$ from $D^*$. By construction, $D_{\mathcal{Z}}'$ is a valid decision tree for $\mathcal{T}_{\mathcal{Z}}$ and as for every $z\in \mathcal{P}_{\mathcal{T}}\br{u, v}$: $c\br{v_{u,v}}\leq c\br{z}$ such strategy has cost at most $\COST_{D_{\mathcal{Z}}'}\br{\mathcal{T}_{\mathcal{Z}}}\leq \OPT\br{\mathcal{T}\angl{\mathcal{Z}}}$. We get:
        $$
        \OPT\br{\mathcal{T}_{\mathcal{Z}}}\leq \COST_{D_{\mathcal{Z}}'}\br{\mathcal{T}_{\mathcal{Z}}}\leq \OPT\br{\mathcal{T}\angl{\mathcal{Z}}}\leq \OPT\br{\mathcal{T}}
        $$

        where the first inequality is due to the optimality and the last inequality is due to the fact that $\mathcal{T}\angl{\mathcal{Z}}$ is a subtree of $\mathcal{T}$ (by Lemma \ref{lemma:subtreeCost}). The lemma follows.
    \end{proof}
\end{lemma}
\begin{lemma}
    Let $D_T$ be the solution returned by the algorithm. Then the approximation factor of such solution is bounded by 
    $
    \APP_T\br{D_T}\leq \log n/\log\log n
    $.
    \begin{proof}
        Let $\mathcal{T}$ be the tree processed at some level of the recursion and let $D_{\mathcal{T}}$ be the decision tree returned by the algorithm. The proof is by induction on the size of $\mathcal{T}$.  We claim that $\APP_{\mathcal{T}}\br{D_{\mathcal{T}}}\leq \max\brc{1, \log n\br{\mathcal{T}}/\log\log n}$. If $n\br{\mathcal{T}}\leq k$ then $D_{\mathcal{T}}$ is the optimal decision tree for $\mathcal{T}$ which establishes the base case. Let $n\br{\mathcal{T}} > k$ and assume that claim holds for every $t< n\br{\mathcal{T}}$. 
        By construction, we have that:
        \begin{align*}
        \APP_{D_{\mathcal{T}}}\br{\mathcal{T}}&=\frac{\COST_{D_{\mathcal{T}}}\br{\mathcal{T}}}{\OPT\br{\mathcal{T}}}\\
        &\leq \frac{\COST_{D_{\mathcal{Z}}}\br{\mathcal{T}}+\max_{H\in \mathcal{T}-\mathcal{Z}}\brc{C_{D_H}\br{H}}}{\OPT\br{\mathcal{T}}}\\
        &\leq 
        \frac{\COST_{D_{\mathcal{Z}}}\br{\mathcal{T}_{\mathcal{Z}}}}{\OPT\br{\mathcal{T}_{\mathcal{Z}}}}+\max_{H\in \mathcal{T}-\mathcal{Z}}\brc{\frac{C_{D_H}\br{H}}{\OPT\br{H}}}\\
        &\leq 1+\frac{\log\frac{n\br{\mathcal{T}}}{\log n\br{\mathcal{T}}}}{\log\log n}= \frac{\log n\br{\mathcal{T}}}{\log\log n}
        \end{align*}
        where the first inequality is by construction, the second is by usage of Observation \ref{observation:CostDZinT}, Lemma \ref{lemma:auxTreeCost} and Lemma \ref{lemma:subtreeCost} and the last inequality is due to the Lemma \ref{lemma:componentSize} and the induction hypothesis.
    \end{proof}
\end{lemma}
    Using the fact that the call to the exponential time procedure requires $O\br{2^{4k-3}\br{4k-3}}=\text{poly}\br{n}$ time (Due to Lemma \ref{lemma:auxTreeSize}), all other computations require polynomial time, and each $v\in V\br{T}$ belongs to $\mathcal{Z}$ at most once during the execution we get that the overall running time is polynomial in $n$.
    \end{proof}
\end{theorem}
In the above analysis we lose one factor of $\OPT$ per each level of recursion of which there are at most $O\br{\log n/\log\log n}$. Notice however, that we can allow some more loss (i. e. $c\cdot\OPT$) without affecting the asymptotical approximation factor. As it turns out it is possible to obtain a constant factor approximation for this problem in quasipolynomial time. This is the main idea behind the improvement of the approximation factor for this problem as in such case the size of the set $\mathcal{Z}$ may be greater and less recursion levels are needed which directly improves the approximation.
\paragraph{An $O\br{\sqrt{\log n}}$-approximation algorithm for $T||V,c||C_{max}$}
We begin with the following proposition \cite{dereniowski2017ApproxSsForGeneralBSinWTs} about the existence of QPTAS for $T||V,c||C_{max}$:
\begin{proposition}\label{QPTAS}
     For any $0 < \epsilon \leq 1$ there exists a $(1+\epsilon)$-approximation algorithm for the Tree Search Problem running in $2^{O\br{\frac{\log^2n}{\epsilon^2}}}$ time.
\end{proposition}
The algorithm and the proof of its correctness are very intricate and requires usage of an alternative notion of strategy. However, we rewrite it to use the language of the decision trees. Since the proof is involved for now we will use it as a black-box. The proof will be differed to a separate paragraph after the analysis below.

\begin{theorem}
    There exists a polynomial time, $O\br{\log n/\log\log n}$-approximation algorithm for the $T||V,c||C_{max}$ problem .
    \begin{proof}
    We use the same procedure as in the $O\br{\log n/\log\log n}$-approximation algorithm, however we set $k=2^{\fl{\sqrt{\log n}}+2}$ and we swap the exact procedure to the QPTAS with $\epsilon=1$. The analysis of the algorithm is largely the same except the evaluation of the cost of this solution.
    \begin{lemma}
        Let $D_T$ be the solution returned by the algorithm. Then the approximation factor of such solution is bounded by 
    $
    \APP_T\br{D_T}\leq 2\sqrt{\log n}
    $.
    \begin{proof}
        Let $\mathcal{T}$ be the tree processed at some level of the recursion and let $D_{\mathcal{T}}$ be the decision tree returned by the algorithm. The proof is by induction on the size of $\mathcal{T}$.  We claim that $\APP_{\mathcal{T}}\br{D_{\mathcal{T}}}\leq \max\brc{1, 2\log n\br{\mathcal{T}}/\sqrt{\log n}}$. If $n\br{\mathcal{T}}\leq k$ then $D_{\mathcal{T}}$ is the optimal decision tree for $\mathcal{T}$ which establishes the base case. Let $n\br{\mathcal{T}} > k$ and assume that claim holds for every $t< n\br{\mathcal{T}}$. 
        By construction, we have that:
        \begin{align*}
        \APP_{D_{\mathcal{T}}}\br{\mathcal{T}}&=\frac{\COST_{D_{\mathcal{T}}}\br{\mathcal{T}}}{\OPT\br{\mathcal{T}}}\\
        &\leq \frac{\COST_{D_{\mathcal{Z}}}\br{\mathcal{T}}+\max_{H\in \mathcal{T}-\mathcal{Z}}\brc{C_{D_H}\br{H}}}{\OPT\br{\mathcal{T}}}\\
        &\leq \frac{\COST_{D_{\mathcal{Z}}}\br{\mathcal{T}_{\mathcal{Z}}}}{\OPT\br{\mathcal{T}_{\mathcal{Z}}}}+\max_{H\in \mathcal{T}-\mathcal{Z}}\brc{\frac{C_{D_H}\br{H}}{\OPT\br{H}}}\\
        &\leq 2+\frac{2\log\frac{n\br{\mathcal{T}}}{\sqrt{\log n}}}{\sqrt{\log n}}= \frac{2\log n\br{\mathcal{T}}}{\sqrt{\log n}}
        \end{align*}
        where the first inequality is by construction, the second is by usage of Observation \ref{observation:CostDZinT}, Lemma \ref{lemma:auxTreeCost} and Lemma \ref{lemma:subtreeCost} and the last inequality is due to the Lemma \ref{lemma:componentSize} and the induction hypothesis.
    \end{proof}
\end{lemma}
    \end{proof}
\end{theorem}
\paragraph{QPTAS for the $T||V,c||C_{max}$ problem}
\begin{observation}\label{basicBoundsOnCost}
    Let $T$ be a tree such that $\spr{V\br{T}}> 1$ and $c:V\to \mathbb{R}^+$ be a normalized weight function. Then, $1\leq \OPT(T) \leq \fl{\log n}+1$.
\end{observation}

\paragraph{Constant factor approximation for monotonic query costs}

\paragraph{$O\br{\log\log n}$-approximation algorithm parametrized by the $k$-up-modularity of the cost function}

Let $s\in\mathbb{R}^+$. We define a \textit{heavy module} with respect to $s$ as $H\subseteq V\br{T}$ such that: $T[H]$ is connected, for every $v \in H$: $c\br{v}\geq s$ and $H$ is maximal - no vertex can be added to it without violating one of its properties. We then define the \textit{heavy module set} of $c$ in $T$ as: $HM_{T,c}\br{s}=\brc{H\subseteq V\br{T}|H \text{ is a heavy module w.r.t. } s}$ (abbreviated to $HM\br{s}$). Let $k\br{T,c}= \max_{s\in\mathbb{R}^+}\brc{\spr{HM_{T,c}\br{s}}}$. We say that a function $c$ is $k$\textit{-up-modular} in $T$, when $k\geq k\br{T,c}$. Whenever clear from the context we will use $k\br{T,c}$, $k\br{T}$, or $k$ to denote the lowest value such that $c$ is $k$-up modular in $T$. 

The notion of $k$-up-modularity is a direct generalization of the concept of up-monotonicity of the cost function. It is easy to see that in fact 1-up-modularity is equivalent to up-monotonicity. Observe that if $c$ is up-monotonic in $T$ then for every $s\in\mathbb{R}^+$: $T[V\br{T}-\brc{v\in V\br{T}: c\br{v}<s}]$ is connected and forms a single heavy module. Conversely, let $r=\argmax_{v\in V\br{T}}\brc{c\br{v}}$ and $u$ be any other vertex. If $c$ is 1-up-modular in $T$ then there is no vertex $v$ on path between $r$ and $u$ such that $c\br{v}<c\br{u}$. If otherwise then for any $s\in \br{v,u}$: $v$ does not belong to any heavy module but $u$ and $r$ do. As $v$ lays between them $\spr{HM\br{s}}>1$, a contradiction.

From now on we will again assume that all weights are normalized, so that the weight of the heaviest vertex is exactly 1. If not, the weights are scaled by dividing them by $\max_{v\in V\br{T}}\brc{w(v)}$.

The main idea of the algorithm is to divide vertices into \textit{cost levels} and process them in a recursive manner. At each level of the recursion the algorithm broadens the subset of vertices of $T$ having queries assigned to them. This continues until every $v\in T$ has a query to it scheduled. We consider the following intervals which we call \textit{cost levels}:
\begin{enumerate}
    \item Firstly, an interval $\left( 0,\frac{1}{\log n}\right]$.
    \item Then, each next interval $\mathcal{I}'=\left(a',b'\right]$ starts at the left endpoint of the previous interval $\mathcal{I}=\left(a,b\right]$, that is, $a'=b$ and ends with $b'=\min\brc{2b, 1}$. This results in the following sequence of intervals:
    $$\left(\frac{1}{\log n},\frac{2}{\log n}\right], \left(\frac{2}{\log n},\frac{4}{\log n}\right],\dots, \left(\frac{2^{\cl{\log\log n}-1}}{\log n},1\right]$$
\end{enumerate} 
After obtaining a solution for previous interval recursively, the next consecutive weight level $\mathcal{I}$ is processed by extending the strategy to contain all queries to vertices $v$ such that $c\br{v}\in \mathcal{I}$.
Once the last interval $\left(\frac{2^{\cl{\log\log n}-1}}{\log n},1\right]$ is processed the algorithm returns a valid decision tree for $T$. 

We are now ready to introduce the notions of heavy and light vertices (and queries to them). We say that a vertex $v$ (or the query to it) is \textit{heavy} with respect to the interval $\mathcal{I}=\left(a,b\right]$, when $c\br{v}>a$. If otherwise, i.e. $c\br{v}\leq a$ then, the vertex (and the query to it) is \textit{light} with respect to $\mathcal{I}$. Whenever clear from the context, we will omit the term "with respect to" and just call the vertices and queries heavy and light.

\input{figures/heavy_module_contraction}
At last, we introduce the contraction operation.
Let $s>c\br{r\br{T}}$ and let $H$ be a heavy module with respect to $s$. Let $v$ be a parent of $r\br{T[H]}$ (observe that such a parent always exists as the tree is rooted at the lightest vertex and $s>c\br{r\br{T}}$).
A \textit{contraction} of a heavy module $H$ is an operation which consists of deleting all of the vertices in $H$ from $T$ and connecting every vertex $u$ which was a child of some vertex in $H$ to $v$ (note, that this definition slightly differs from the standard contraction, for example see Figure \ref{exampleHeavymoduleContraction}). This leads to the following simple observations:

\begin{observation}
\label{monotonicityOfOptContraction}
    Let $T'$ be a tree created by contraction of a heavy module $H$ in $T$. Then, $\OPT\br{T'}\leq \OPT\br{T}$.
\end{observation}
\begin{observation}\label{monotonicityOfKContracion}
    Let $T'$ be a tree created by contraction of a heavy module $H$ in $T$. Then, $k\br{T'}\leq k\br{T}$.
\end{observation}


We are ready to present the main recursive procedure. To avoid ambiguity, let $\mathcal{T}$ be the tree processed at some level of the recursion. Alongside $\mathcal{T}$, the algorithm takes as an input the interval $\left(a,b\right]$ such that for every $v\in \mathcal{T}$: $c\br{v}\leq b$. 
% For simplicity, we will say that vertices or modules are heavy when they are heavy with respect to $\left(a,b\right]$. 
The algorithm (see Algorithm \ref{createDecisionTree}) works in the following manner: 

\input{pseudocodes/main_parametrized}
\begin{itemize}
    \item The base case happens whenever for every $v\in\mathcal{T}$: $c\br{v}\leq\frac{1}{\log n}$ or for every $v\in\mathcal{T}$: $c\br{v}>a$, i.e. every vertex is heavy. In such situation a solution is build by disregarding the costs of vertices and building a decision tree by using the vertex ranking of $\mathcal{T}$. 
    \item If otherwise, all heavy modules in $\mathcal{T}$ are contracted, forming a new tree $\mathcal{T}_C$ and a decision tree $D_{C}$ for $\mathcal{T}_C$ is built in a recursive manner. By applying the following proposition, the decision tree $D$ for $\mathcal{T}$ is build by extending $D_{C}$ to contain queries to all vertices in $\mathcal{T}$:
\end{itemize}
\begin{proposition}
\label{existanceOfExtensionAlgorithm}
There exists the algorithm \texttt{ExtendDecTree} which given a tree $\mathcal{T}$, a decision tree $D_C$ for $\mathcal{T}_C$ and an interval $\left(a,b\right]$ returns decision tree $D$ for $\mathcal{T}$ of cost at most:
$
\COST_{D}\br{\mathcal{T}}\leq \COST_{D_C}\br{\mathcal{T}_C}+\br{2+\frac{b}{a}}\cdot\OPT\br{\mathcal{T}}
$.
The algorithm runs in time 
$2^{O\br{\log^2k}}\cdot\text{poly}\br{n}$.   
\end{proposition}

The algorithm and the proof of the Proposition \ref{existanceOfExtensionAlgorithm} are differed to further paragraph. 

\begin{lemma}\label{baseOfRecursion}
    Let $D$ be a decision tree build for $\mathcal{T}$ in the base of the recursion in \textsc{CreateDecisionTree} by using the vertex ranking of $\mathcal{T}$. Then:
$
\COST_{D}\br{\mathcal{T},c}\leq 2\OPT(T)
$.
\begin{proof}
    There are two cases:
    \begin{enumerate}
        \item If $b\leq \frac{1}{\log n}$ we get that:
$$
\COST_{D}\br{\mathcal{T},c}\leq\frac{\fl{\log n}+1}{\log n}\leq 2\leq 2\OPT(\mathcal{T},c)\leq 2\OPT(T,c)
$$

where the first inequality is due to the definition of the vertex ranking, the third inequality is due to Observation \ref{basicBoundsOnCost} and the last inequality is due to Observation
\ref{monotonicityOfOptContraction}.
\item 
If for every ${v\in \mathcal{T}} $: $c\br{v}> a$ then: For every $v\in \mathcal{T}$ let $c'\br{v}=a$ (note, that we can choose any cost here since we treat each query as unitary). As $2c'\br{v}\geq2a=b \geq c\br{v}$ we get that $2\COST_D\br{\mathcal{T}, c'}\geq \COST_D\br{\mathcal{T}, c}$. Additionally, using the fact that $c'\br{v} \leq c\br{v}$ we get that $\OPT\br{\mathcal{T}, c'}\leq \OPT\br{\mathcal{T}, c}$. Therefore:
$$
\COST_D\br{\mathcal{T}, c}\leq 2\COST_D\br{\mathcal{T}, c'}=2\OPT\br{\mathcal{T}, c'}\leq 2\OPT\br{\mathcal{T}, c}\leq 2\OPT\br{T, c}
$$

where the equality is due to the optimality of decision tree built using the vertex ranking and the last inequality is due to Observation \ref{monotonicityOfKContracion}. The lemma follows.
    \end{enumerate}
\end{proof}
\end{lemma}

We are now ready to prove the main theorem: 
\begin{theorem}
\label{parametrizedAlgorithm}
    There exists an $O\br{\log\log n}$-approximation algorithm for the Tree Search Problem running in $2^{O\br{\log^2k\br{T}}}\cdot\text{poly}\br{n}$ time.
    \begin{proof}
    Let $d$ be the depth of recursion call performed in the algorithm. We prove by induction that $\COST_{D}\br{\mathcal{T}}\leq \br{4d +2}\OPT\br{T}$. When $d=0$ (the base case) the induction hypothesis is true due to the Lemma \ref{baseOfRecursion}. For $d>0$ assume by induction that the cost of the decision tree build for $D_C$ is at most $\COST_{D_C}\br{\mathcal{T}_C}\leq \br{4(d-1) +2}\OPT\br{T}$. By using induction hypothesis and the fact that whenever \texttt{ExtendDecTree} is called $\frac{b}{a}\leq 2$ we get that:
    $$
    \COST_{D}\br{\mathcal{T}}\leq \br{4\cdot (d-1) +2}\OPT\br{\mathcal{T}} + 4\OPT\br{\mathcal{T}} \leq \br{4d +2}\OPT\br{T}
    $$ 

    where the first inequality is due to the induction hypothesis and Proposition \ref{existanceOfExtensionAlgorithm} and the second inequality is due to Observation \ref{monotonicityOfOptContraction}. This proves the induction step.
    
    Let $D_T$ be a decision tree obtained by calling $\texttt{CreateDecisionTree}\br{T,\left(\frac{2^{\cl{\log\log n}-1}}{\log n},1\right]}$. As there are $\cl{\log\log\br{n}}+1$ intervals considered, the depth of recursion is bounded by $d\leq
    \cl{\log\log\br{n}}\leq \log\log\br{n}+1$. We obtain:
    $$
    \COST_{D_T}\br{T}
    \leq
    \br{4\log\log n + 6}\OPT\br{T} = O\br{\log\log n\cdot \OPT\br{T}}
    $$

    As $d=\text{poly}\br{n}$ and due to Observation \ref{monotonicityOfKContracion} for every $\mathcal{T}$ processed at some level of the recursion $k\br{\mathcal{T}}\leq k\br{T}$. Using the Proposition \ref{existanceOfExtensionAlgorithm}, we get that for every $d$ the algorithm runs in $2^{O\br{\log^2k\br{\mathcal{T}}}}\cdot\text{poly}\br{n}$, so the overall running time is bounded by $d\cdot2^{O\br{\log^2k\br{T}}}\cdot\text{poly}\br{n}=2^{O\br{\log^2k\br{T}}}\cdot\text{poly}\br{n}$ as required.
        
    \end{proof}
\end{theorem}
\paragraph{Proof of Proposition \ref{existanceOfExtensionAlgorithm}: Extending the decision tree}

We prove Proposition \ref{existanceOfExtensionAlgorithm} by showing the procedure \texttt{ExtendDecTree} which takes as an input: the tree $\mathcal{T}$, the partial decision tree $D_C$ for the contracted tree $\mathcal{T}_C$ and the interval $\left(a,b\right]$ and extends $D_C$ to contain all queries needed to find any target $x\in \mathcal{T}$. The basic idea of the algorithm is as follows: 
\begin{enumerate}
    \item Create an auxiliary tree $T_{\mathcal{Z}}$ such that each subtree $\mathcal{T}'\in \mathcal{T}-\mathcal{Z}$ contains at most one heavy module and create a new decision tree $D_{\mathcal{Z}}$ for $\mathcal{T}_{\mathcal{Z}}$.
    \item For each $\mathcal{T}'$ build a decision tree $D_H$ for the subtree $T\angl{H}$ induced by its heavy module $H$ by using the vertex ranking of $H$. Then hang $D_H$ below the last query to vertex from $N_{\mathcal{T}}\br{\mathcal{T}'}$ in $D_{\mathcal{Z}}$.
    \item For each $L\in\mathcal{T}'-H$ build a decision tree $D_L$ by truncating queries to vertices outside of $L$ from $D_C$. Then hang $D_L$ below the last query to vertex from $N_{\mathcal{T'}}\br{L}$ in $D_{\mathcal{Z}}$.
\end{enumerate}

We begin with the following observations:
\begin{observation}
Let $\mathcal{H}$ be the set of heavy modules in $\mathcal{T}$. Then, $\spr{\mathcal{H}}\leq k\br{\mathcal{T}}$.
\end{observation}

To build a solution (see Algorithm \ref{extensionProcedure}) we will firstly define a set $\mathcal{X}\subseteq V\br{\mathcal{T}}$. For every $H\in\mathcal{H}$ pick arbitrary $v\in H$ and add it to $\mathcal{X}$. We also define set $\mathcal{Y}\subseteq V\br{\mathcal{T}}$ which consists of vertices in $\mathcal{X}$ and all vertices in $v\in \mathcal{T}\angl{X}$ such that $\deg_{T\angl{\mathcal{X}}}\br{v}\geq 3$. 

Furthermore, we define set $\mathcal{Z}\subseteq V\br{\mathcal{T}}$ as a set consisting of vertices in $\mathcal{Y}$ and for every $u,v\in \mathcal{Y}$ such that $\mathcal{P}_{\mathcal{T}}\br{u, v}\neq\emptyset$ and $\mathcal{P}_{\mathcal{T}}\br{u, v}\cap \mathcal{Y}=\emptyset$ we add to $\mathcal{Z}$ the vertex $\argmin_{z\in \mathcal{P}_{\mathcal{T}}\br{u, v}}\brc{c\br{z}}$ (for example see Figure \ref{exampleTreeWithSetZ}). We then create an auxiliary tree $\mathcal{T}_{\mathcal{Z}}=\br{\mathcal{Z},\brc{uv|\mathcal{P}_{\mathcal{T}}\br{u, v}\cap \mathcal{Z}=\emptyset}}$ (for example see Figure \ref{exampleAuxTreeTZ}). The algorithm builds a decision tree $D_{\mathcal{Z}}$ for $\mathcal{T}_{\mathcal{Z}}$ by taking $\epsilon=1$ and applying the QPTAS from Theorem \ref{QPTAS}. Observe, that  $D_{\mathcal{Z}}$ is a  partial decision tree for $\mathcal{T}$, so we get that:
\begin{observation}\label{CostDZinTObservation}
    $\COST_{D_{\mathcal{Z}}}\br{\mathcal{T}_{\mathcal{Z}}}=\COST_{D_{\mathcal{Z}}}\br{\mathcal{T}}$.
\end{observation}

Let $D = D_{\mathcal{Z}}$. For each connected component $\mathcal{T}'\in \mathcal{T}-\mathcal{Z}$ we build a new decision tree in the following way: By construction of $\mathcal{Z}$, heavy vertices in $\mathcal{T}'$ form a singular heavy module $H\subseteq V\br{\mathcal{T}'}$. We create a new decision tree $D_H$ for $\angl{H}$ by using the vertex ranking of $\mathcal{T}\angl{H}$ and we hang $D_{H}$ in $D$ below the unique last query to a vertex in $N_\mathcal{T}\br{\mathcal{T}'}$ (By Observation \ref{neighborsPathObservation}). As $D_H$ is a partial decision tree for $\mathcal{T}'$, it follows that $D$ is also a partial decision tree for $\mathcal{T}$. Then for each $L\in \mathcal{T}'-H$ we create a decision tree $D_L$ by deleting all queries in $D_C$ to vertices outside of $V\br{L}$ and hang $D_L$ in $D$ below the unique last query to vertex in $N_{\mathcal{T}'}\br{L}$ (By Observation \ref{neighborsPathObservation}). As $D_L$ is a decision tree for $L$, we obtain a valid decision tree $D$ for $\mathcal{T}$.

\begin{lemma}\label{auxTreeSizeLemma}
    Let $\mathcal{T}_{\mathcal{Z}}$ be the auxiliary tree. Then, $\spr{V\br{\mathcal{T}_{\mathcal{Z}}}}\leq 4k-3$.
    \begin{proof}
        We firstly show that $\spr{\mathcal{Y}}\leq 2k-1$. We use induction on elements of set $\mathcal{H}$. We will construct a family of sets $\mathcal{H}_1, \mathcal{H}_2,\dots, \mathcal{H}_{\spr{\mathcal{H}}}$ such that for any $1\leq h\leq \spr{\mathcal{H}}$: $\spr{\mathcal{H}_h}=h$ and $\mathcal{H}_{\spr{\mathcal{H}}}=\mathcal{H}$. For each $\mathcal{H}_h$ we will also construct a corresponding set $\mathcal{Y}_h$, ensuring $\mathcal{Y}_{\spr{\mathcal{H}}}=\mathcal{Y}$.
        
        Let $\mathcal{H}_1=\emptyset$, $\mathcal{Y}_1=\emptyset$. Pick any heavy module $H\subseteq V\br{\mathcal{T}}$ and add it to $\mathcal{H}_1$. Additionally, add the unique vertex in $H\cap\mathcal{X}$ to $\mathcal{Y}$, so that $\spr{\mathcal{Y}_1}=1$. Assume by induction on $h\geq1$ that $\spr{\mathcal{Y}_h}\leq 2h-1$. We say that heavy modules $H_1,H_2\subseteq V\br{\mathcal{T}}$ are \textit{neighbors} when for every heavy module $H_3\subseteq V\br{\mathcal{T}}$ such that $H_3\neq H_1,H_2$: $P_{\mathcal{T}}\br{H_1,H_2}\cap H_3=\emptyset$.
        Let $H\subseteq V\br{\mathcal{T}}$ such that $H\notin \mathcal{H}_h$ be a heavy module which is a neighbor of some heavy module in $\mathcal{H}_h$. Let $\mathcal{H}_{h+1}=\mathcal{H}_h\cup\brc{H}$.  Let $z$ be the unique vertex in $H\cap\mathcal{X}$ and $\mathcal{Y}_{h+1}=\mathcal{Y}_{h}\cup\brc{z}$. Let $\mathcal{T}_{h+1}=\mathcal{T}\angl{\brc{v\in \mathcal{Y}_{h+1}|\mathcal{P}_\mathcal{T}\br{v,z}\cap \mathcal{Y}_{h+1}=\emptyset}}$. Notice, that $\mathcal{T}_{h+1}$ is a spider (tree with at most one vertex with degree above 3). Add to $\mathcal{Y}_{h+1}$ the unique vertex $v\in \mathcal{T}_{h+1}$ such that $\deg_{\mathcal{T}_{h+1}}\br{v}\geq 3$ if it exists. Clearly, $\spr{\mathcal{Y}_{h+1}}\leq2h+1$, so the induction step is complete. By construction, eventually $\mathcal{H}_{\spr{\mathcal{H}}}=\mathcal{H}$ and $\mathcal{Y}_{\spr{\mathcal{H}}}=\mathcal{Y}$, so in consequence $\spr{\mathcal{Y}}\leq 2\spr{\mathcal{H}}-1\leq 2k-1$.
        
        As paths between vertices in $\mathcal{Y}$ form a tree, at most $2k-2$ additional vertices are added to $\mathcal{Y}$ while constructing $\mathcal{Z}$ (at most one for each path) and the lemma follows.
    \end{proof}
\end{lemma}

\input{pseudocodes/extension_procedure}
\input{figures/auxiliary_tree_extension}
\begin{lemma}\label{auxTreeCostLemma}
    Let $\mathcal{T}_{\mathcal{Z}}$ be the auxiliary tree. Then, $\OPT\br{\mathcal{T}_{\mathcal{Z}}}\leq \OPT\br{\mathcal{T}}$.
    \begin{proof}
        Let $D^*$ be the optimal strategy for $\mathcal{T}\angl{\mathcal{Z}}$. We build a new decision tree $D_{\mathcal{Z}}'$ for $\mathcal{T}_{\mathcal{Z}}$ by transforming $D^*$: Let $u,v\in \mathcal{Y}$ such that $\mathcal{P}_{\mathcal{T}}\br{u, v}\neq\emptyset$ and $\mathcal{P}_{\mathcal{T}}\br{u, v}\cap \mathcal{Y}=\emptyset$. Let $q\in V\br{D^*}$ such that $q\in \mathcal{P}_{\mathcal{T}}\br{u, v}$ is the first query among vertices of $\mathcal{P}_{\mathcal{T}}\br{u, v}$. We replace $q$ in $D^*$ by the query to the distinct vertex $v_{u,v}\in \mathcal{P}_{\mathcal{T}}\br{u, v}\cap \mathcal{Z}$ and delete all queries to vertices $\mathcal{P}_{\mathcal{T}}\br{u, v}-v_{u,v}$ from $D^*$. By construction, $D_{\mathcal{Z}}'$ is a valid decision tree for $\mathcal{T}_{\mathcal{Z}}$ and as for every $z\in \mathcal{P}_{\mathcal{T}}\br{u, v}$: $c\br{v_{u,v}}\leq c\br{z}$ such strategy has cost at most $\COST_{D_{\mathcal{Z}}'}\br{\mathcal{T}_{\mathcal{Z}}}\leq \OPT\br{\mathcal{T}\angl{\mathcal{Z}}}$. We get:
        $$
        \OPT\br{\mathcal{T}_{\mathcal{Z}}}\leq \COST_{D_{\mathcal{Z}}'}\br{\mathcal{T}_{\mathcal{Z}}}\leq \OPT\br{\mathcal{T}\angl{\mathcal{Z}}}\leq \OPT\br{\mathcal{T}}
        $$

        where the first inequality is due to the optimality and the last inequality is due to the fact that $\mathcal{T}\angl{\mathcal{Z}}$ is a subtree of $\mathcal{T}$ (by Lemma \ref{lemma:subtreeCost}). The lemma follows.
    \end{proof}
\end{lemma}

\begin{lemma}
    $\COST_D\br{\mathcal{T}}\leq\COST_{D_C}\br{\mathcal{T}_C}+\br{2+\frac{b}{a}}\OPT\br{\mathcal{T}}$
    \begin{proof}
    Let $H\subseteq V\br{\mathcal{T}}$ be a heavy module. We show that: $\COST_{D_H}\br{\mathcal{T}\angl{H}}\leq \frac{b}{a}\cdot\OPT\br{\mathcal{T}, c}$. For every $v\in H$ let $c'\br{v}=a$ (note, that we can choose any cost here since we treat each query as unitary). As $\frac{bc'\br{v}}{a}\geq b \geq c\br{v}$ we get that $\frac{b}{a}\cdot\COST_{D_H}\br{\mathcal{T}\angl{H}, c'}\geq \COST_{D_H}\br{\mathcal{T}\angl{H}, c}$. Additionally, using the fact that $c'\br{v} \leq c\br{v}$ we get that $\OPT\br{\mathcal{T}\angl{H}, c'}\leq \OPT\br{\mathcal{T}\angl{H}, c}$. Therefore:
    $$
    \begin{gathered}
        \COST_{D_H}\br{\mathcal{T}\angl{H}, c}\leq \frac{b}{a}\cdot\COST_{D_H}\br{\mathcal{T}\angl{H}, c'}=\frac{b}{a}\cdot\OPT\br{\mathcal{T}\angl{H}, c'}\leq \\
        \leq
        \frac{b}{a}\cdot\OPT\br{\mathcal{T}\angl{H}, c}\leq \frac{b}{a}\cdot\OPT\br{\mathcal{T}, c}
    \end{gathered}
    $$
        
    where the last inequality is due to the fact that $\mathcal{T}\angl{H}$ is a subtree of $\mathcal{T}$ (by Lemma \ref{subtreeCostLemma}).
        
    Let $Q_D\br{\mathcal{T},x}$ be a sequence of queries performed in order to find target $x$. By construction of the Algorithm \ref{extensionProcedure}, $Q_D\br{\mathcal{T},x}$ consists of at most three distinct subsequences of queries (some subsequences might be empty). Firstly, there is a sequence of queries belonging to $Q_{D_{\mathcal{Z}}}\br{\mathcal{T}_{\mathcal{Z}},x}$. If $x\notin \mathcal{Z}$, then it is followed by a sequence of queries belonging to $Q_{D_{H}}\br{\mathcal{T}\angl{H},x}$ such that $H\in \mathcal{T}'$ is a heavy module and $x\in \mathcal{T}'$. If $x\notin H$, at last, there is a sequence of queries belonging to $Q_{D_{L}}\br{L,x}$ for $L\in \mathcal{T}'-H$ such that $x\in L$. 
    We have:
        \begin{align*}
        \COST_D\br{\mathcal{T}}&\leq
        \COST_{D_{\mathcal{Z}}}\br{\mathcal{T}}+\max_{\mathcal{T}'\in \mathcal{T}-\mathcal{Z}}\brc{\COST_{D_H}\br{\mathcal{T}\angl{H}}+\max_{L\in \mathcal{T}'-H}\brc{\COST_{D_L}\br{L}}}
        \\ 
        &\leq
        \COST_{D_{\mathcal{Z}}}\br{\mathcal{T}_{\mathcal{Z}}}+\max_{\mathcal{T}'\in \mathcal{T}-\mathcal{Z}}\brc{\frac{b}{a}\cdot\OPT\br{\mathcal{T}}+\COST_{D_C}\br{\mathcal{T}_C}}
        \\
        &\leq
        2\OPT\br{\mathcal{T}_{\mathcal{Z}}}+\frac{b}{a}\cdot\OPT\br{\mathcal{T}}+ \COST_{D_C}\br{\mathcal{T}_C} \leq \COST_{D_C}\br{\mathcal{T}_C} + \br{2+\frac{b}{a}}\cdot\OPT\br{\mathcal{T}}
        \end{align*}

        where the first inequality is due to the construction of the returned decision tree, the second is due to Observation \ref{CostDZinTObservation} and due to the fact that $L$ is a subtree of $\mathcal{T}_C$ (Lemma \ref{lemma:subtreeCost}), the third is due is due to Theorem \ref{QPTAS} and the last is due to Lemma \ref{auxTreeCostLemma}.
        
    \end{proof}
\end{lemma}

Using Lemma \ref{auxTreeSizeLemma} we get that the QPTAS runs in time $2^{O\br{\log^2\br{4k\br{\mathcal{T}}}}}=2^{O\br{\log^2\br{k\br{\mathcal{T}}}}}$ and all other computations can be performed in polynomial time which completes the proof of the Proposition \ref{existanceOfExtensionAlgorithm}.

\subsection{Average case, non-uniform weights}
In this section we show how to obtain a constant factor approximation for the $T||V,c,w||\sum C_i$ problem. Since the problem is NP-hard, one should not hope for a polynomial time exact solution (The proof of this fact is differed to the appendix). However, even constant factor approximation is quite surprising as in contrast, recall that the state-of-the-art algorithm for $T||V,c||C_{max}$ achieves only much weaker, $O\br{\sqrt{\log n}}$-approximation. The idea behind the solution is inspired by the work of \cite{Approximatehierarchicalclusteringviasparsestcutandspreadingmetrics} and \cite{kseparator}. In order to tightly lower bound the cost of the optimum we use the connection of the problem to the following weighted $\alpha$-separator problem which is a generalization of the $k$-separator problem introduced in \cite{kseparator}:
\paragraph{Weighted $\alpha$-separator problem}
\begin{tcolorbox}[colback=white, title=Weighted $\alpha$-separator problem, fonttitle=\bfseries, breakable]
\paragraph{Input:} Graph $G=\br{V\br{G}, E\br{G}}$, the weight function $w:V\to \mathbb{N}^+$, the cost function $c:V\to \mathbb{N}^+$ and a real number $\alpha$.
\paragraph{Output:} A set $S\subseteq V\br{G}$ called \textit{separator} such that for every $H\in G-S$: $w\br{S}\leq w\br{G}/\alpha$ and $c\br{S}$ is minimized.
\end{tcolorbox}

Note that the authors of \cite{kseparator} use an alternative definition for the unweighted version of the problem in which the size of each $H\in G-S$ is required to be $\spr{H}\leq k$. As we are concerned with the more general variant of the problem it is easier for us to use our definition. Given the value $\alpha$ or $k$ one can obtain the other by simply using the fact that the problems are equivalent when $k=w\br{G}/\alpha$. We will use these two notions whenever more comfortable. Note that for the special case when $\alpha=0$ we have that $k=\infty$ and the optimal separator for $G$ is $\emptyset$.

For the sake of our analysis we will be only concerned with the variant in which the underlying graph is a tree. When the weights are uniform, this problem is solvable in polynomial time \cite{kseparator}. 
If otherwise, the problem is (weakly) NP-hard. The proof of this fact is differed to the appendix. Despite the hardness of the problem we show that it can be solved in a pseudopolynomial time by means of dynamic programming.


\begin{theorem}
    There exists a $O\br{n\br{\min\brc{c\br{T}, w\br{T}/\alpha}}^2}$ time algorithm for the Weighted $\alpha$-separator Problem.
    \begin{proof}
        We use separate subprocedures depending on which of the values $c\br{T}, w\br{T}$ is smaller. Both of them are inspired by the polynomial time algorithm for the unweighted version of the problem \cite{kseparator}. We assume that that the input tree is rooted in an arbitrary vertex $r$. For any vertex $v\in V\br{T}$ let $\mathcal{C}_T\br{v}=\brc{c_1,c_2,\dots,c_{\deg_v^+}}$.
        \begin{enumerate}
            \item $w\br{T}/\alpha\leq c\br{T}$. Let $C_{v}$ be the cost of the optimal separator of the subtree $T_v$. Define $C_{v}^{in}$ as the cost of the optimal $\alpha$-separator $S$ under the condition that $v$ belongs to $S$. We immediately have the following relationship:
            $$
            C_{v}^{in} = c\br{v}+\sum_{c\in \mathcal{C}\br{v}}C_{c}
            $$
            Assume that $v\notin S$. Let $H^v\in T-S$ such that $v\in H^v$. For each $1\leq w\leq k$ let $C_v^{out}\br{w}$ denote the cost of the optimal $\alpha$-separator $S$ such that $v\notin S$ and $w\br{H^v} = w$. We have that:
            $$
            C_v = \min\brc{C_{v}^{in},\min_{1\leq w\leq k}C_v^{out}\br{w}}
            $$
            
            For any vertex $v\in V\br{T}$ and any number $1\leq i\leq \deg_v^+$ let $H_{v,i}\in T_{v,i}-S$ such that $v\in H_{v,i}$. Additionally, for any number $1\leq w\leq k$ let $C_{v,i}^{out}\br{w}$ denote the weight of an optimal $\alpha$-separator such that $v\notin S$ and $w\br{H_i^v} = w$. We have that: 
            $$
            C_{v}^{out}\br{w}=C_{v,\deg_v^+}^{out}\br{w}
            $$
            $$
            C_{v,1}^{out}\br{w}=\begin{cases}
                \infty, & \text{if } w < w\br{v}\\
                C_{c_1}^{in}, & \text{if } w = w\br{v}\\
                C_{c_1}^{out}\br{w-w\br{v}}, & \text{if } w > w\br{v}\\
            \end{cases}
            $$
            $$
            C_{v,i}^{out}\br{w}=\min\brc{C_{v,i-1}^{out}\br{w}+C_{c_i}^{in}, \min_{1\leq j\leq w-1}\brc{C_{v,i-1}^{out}\br{w-j}+C_{c_i}^{out}\br{j}}}
            $$
            Where in the last equality the  first term of the minimum function represents a situation in which $c_i\in S$. In such case all of the weight of $H_{v, i}$ belongs to $H_{i-1}^v$. The second term assumes contrary and checks all possible partitions of the weight between $T_{v, i-1}$ and $T_{c_i}$.

            The relationships above suffice to calculate the value of $C_{r}$ which is the cost of the optimal separator $S$. The computation is performed in a bottom-up, left to right manner starting with the leafs. To finish the description of the algorithm we observe then when this is the case ($v$ is a leaf) we have that $C_v^{in}=c\br{v}$, $C_v^{out}\br{w}=0$, $C_v = 0$ and all other values are equal to $\infty$.

            As there are $O\br{nw\br{T}/\alpha}$ subproblems and each of them requires at most $w\br{T}/\alpha$ computational steps we obtain that the running time is  $O\br{n\br{w\br{T}/\alpha}^2}$.
            \item $w\br{T}/\alpha\geq c\br{T}$. For $v\in V\br{T}$ and $1\leq c\leq c\br{T}$ let $W_{v}\br{c}$ be the optimal weight of $H_v$ in the separator of the subtree $T_v$ of cost at most $c$. Let $B\br{v, c}$ be a boolean value defined as:
            $$
            B_{v}\br{c}=\begin{cases}
                0, & \text{if } W_{v}\br{c} \leq k\\
                1, & \text{if } W_{v}\br{c} > k\\
            \end{cases}
            $$
            Define a boolean value $B_{v}^{in}\br{c}$ to be $0$: if there exists a separator of the subtree $T_v$ of cost at most $c$ under the condition that $v$ belongs to $S$ and $1$ if otherwise. For $1\leq i\leq \deg_{v}^+$ we also define a boolean value $B_{v, i}^{in}\br{c}$ to be $0$: if there exists a separator of the subtree $T_{v,i}$ of cost at most $c$ under the condition that $v$ belongs to $S$ and $1$ if otherwise. Of course $B_{v}^{in}\br{c}=B_{v, \deg_v^+}^{in}\br{c}$. We have the following relationships:
            $$
            B_{v,1}^{in}\br{c}=\begin{cases}
                1, & \text{if } c < c\br{v}\\
                B_{c_1}\br{c-c\br{v}}, & \text{if } c \geq c\br{v}\\
            \end{cases}
            $$
            $$
            B_{v, i}^{in}\br{c} = \min_{1\leq j\leq c}\brc{B_{v, i-1}^{in}\br{c-j}\lor B_{c_i}\br{j}}
            $$
            For each $1\leq c\leq c\br{T}$ let $W_v^{out}\br{w}$ denote the optimal weight of $H^v$ in the separator of the subtree $T_v$ of cost at most $c$ under assumption that $v\notin S$. We have that:
            $$
            W_v\br{c} = \begin{cases}
                0, & \text{if } \neg B_{v}^{in}\br{c}\\
                W_v^{out}\br{c}, & \text{otherwise }
            \end{cases}
            $$
            
            For any vertex $v\in V\br{T}$ and for any number $1\leq c\leq c\br{T}$ let $W_{v,i}^{out}\br{c}$ denote the optimal weight of $H_i^v$ in the separator of the subtree $T_{v,i}$ of cost at most $c$ under assumption that $v\notin S$. We have that: 
            $$
            W_{v}^{out}\br{c}=W_{v,\deg_v^+}^{out}\br{c}
            $$ 
            If $v$ has only one child we have that:
            $$
            W_{v,1}^{out}\br{c}=\begin{cases}
                \infty, & \text{if } B_{c_1}^{in}\br{c}\\
                w\br{v} + W_{c_1}\br{c}, & \text{otherwise } \\
            \end{cases}
            $$
            It is also easy to see that for $i>1$ we have:
            $$
            W_{v,i}^{out}\br{c}=\min_{1\leq j\leq c}\brc{W_{v,i-1}^{out}\br{c-j}+W_{c_i}\br{j}}
            $$
            
            To obtain the cost of the optimal separator we calculate the value $\min\brc{1\leq c \leq c\br{T} | B_{r}\br{c}=0}$ which is the minimal value for which a valid separator of cost at most $c$ exists. The computation is performed in a bottom-up, left to right manner starting with the leafs. To finish the description of the algorithm we observe then when this is the case ($v$ is a leaf) we have that: 
            $$
            B_v^{in}\br{c}=\begin{cases}
                0, & \text{if } c=c\br{v}\\
                1, & \text{otherwise }\\
            \end{cases}$$
            And also:
            $$
            W_v^{out}\br{c}=\begin{cases}
                w\br{v}, & \text{if } c=0\\
                \infty, & \text{otherwise }\\
                \end{cases}
            $$

            As there are $O\br{nc\br{T}}$ subproblems and each of them requires at most $c\br{T}$ computational steps we obtain that the running time is  $O\br{nc\br{T}^2}$.
        \end{enumerate}
        
         To obtain not only the value of the optimum but also a solution, in both cases, by using a standard tabling one is able to store the information about the vertices belonging to the optimal separator for all calculated subproblems.
    \end{proof}
\end{theorem}
    We would like to use the previously shown procedure the create a constant-factor approximation algorithm for $T||V,c,w||\sum C_i$. However, the running time of this algorithm may not be polynomial if both $c\br{T}$ and $w\br{T}$ are of order $\omega\br{\text{poly}\br{n}}$. To alleviate this difficulty we will use a fairly standard rounding trick which will provide us with  a bi-criteria FPTAS for the weighted $\alpha$-separator.
    
    Let $\OPT_\alpha$ be the cost of the optimal solution for the chosen value of $\alpha$. We will still require that the cost of the returned solution will be at most $\OPT_\alpha$. However, we will relax the condition demanding that $H\in T-S$: $w\br{H}\leq \frac{w\br{T}}{\alpha}$ and we will only require that $w\br{H}\leq \frac{\br{1+\delta}w\br{T}}{\alpha}$ for some chosen value of $\delta$. 
\begin{theorem}
    Let $S^*$ be an optimal weighted $\alpha$-separator for $\br{T,c,w,\alpha}$. For any $\delta>0$ there exists an algorithm which returns a separator $S$ such that:
    \begin{enumerate}
        \item $w\br{H}\leq \frac{\br{1+\delta}\cdot w\br{T}}{\alpha}$ for every $H\in T-S$.
        \item $c\br{S}\leq c\br{S^*}$.
    \end{enumerate}
    The algorithm runs in $O\br{n^3/\delta^2}$ time.
    \begin{proof}
        The procedure is as follows:
        \begin{enumerate}
            \item Let $K=\frac{\delta W}{n\alpha}$, for every $v\in V\br{T}$: $w'\br{v} = \fl{\frac{w\br{v}}{K}}$, $w'\br{T}=\sum_{v\in V\br{T}}w'\br{v}$ and $\alpha'=\frac{w'\br{T}K\alpha}{w\br
            T}$.
            \item Return the optimal separator $S$ for $\br{T, w', c, \alpha'}$ found using the $O\br{n\br{\frac{W}{\alpha}}^2}$ time algorithm.
        \end{enumerate}
        \begin{lemma}
            Let $S^*$ be the optimal separator for the original instance. $C\br{S}\leq C\br{S^*}$.
            \begin{proof}
                We prove that $S^*$ is a valid separator for the $\br{T, w', c, \alpha'}$ instance. 
                Recall that $k=W\br{T}/\alpha$.
                To simplify the analysis we introduce the auxiliary instance with values: $$
                w''\br{v} = \fl{\frac{w\br{v}}{K}}\cdot K, 
                w''\br{T}=\sum_{v\in V\br{T}}w''\br{v}, k'' = k \text{ and consequently: } \alpha'' = \frac{w''\br{T}}{k''}=\frac{\alpha w''\br{T}}{w\br{T}}$$
                
                Notice that in this new instance the absolute threshold for required size of each $H \in T-S^*$ has not changed ($k'' = k$) and for every $v\in V\br{T}$: $w''\br{v}\leq w\br{v}$.  Therefore we have that $w''\br{H}\leq w\br{H}\leq k\leq \frac{w''\br{T}}{\alpha''}$. Now notice that the one prim instance has all of its weights scaled by a constant value of $K$ and the relative factor of $\alpha' = \alpha''$. As multiplying by a constant does not influence the validity of a solution $S^*$ is a valid $\alpha'$-separator for $\br{T, w', c, \alpha'}$. Additionally, as the costs remained unchanged and $S$ is optimal for $\br{T, w', c, \alpha'}$ the claim follows.
            \end{proof}
        \end{lemma}
        \begin{lemma}
            For every $H\in T-S$ we have that $w\br{H}\leq\frac{\br{1+\delta}w\br{T}}{\alpha}$.
            \begin{proof}
                By definition we have that $w'\br{v}\leq \frac{w\br{v}}{K}\leq w'\br{v}+1$ and therefore also $Kw'\br{v}\leq w\br{v}\leq Kw'\br{v}+K$. We have that:
                $$
                \sum_{v\in H}w\br{v}\leq K\cdot\sum_{v\in H}w'\br{v}+Kn\leq \frac{Kw'\br{T}}{\alpha'}+nK = \frac{w\br{T}}{\alpha} + \frac{\delta w\br{T}}{\alpha}=\frac{\br{1+\delta}w\br{T}}{\alpha}
                $$
                
                where the second inequality is due to the fact that $S$ is a $\alpha'$-separator for $\br{T, w'\br{T}, c, \alpha'}$ instance.
            \end{proof}
        \end{lemma}
        
        Combining the two above lemmas with the fact that $\frac{w'\br{T}}{\alpha'}=\frac{w\br{T}}{K\alpha}=\frac{n}{\delta}$ we have that the algorithm runs in time $O\br{n^3/\delta^2}$ as required.
    \end{proof}
\end{theorem}
\paragraph{Constant-factor approximation for $T||V, w, c||\sum C_i$}
    As it turns out the $T||V, w, c||\sum C_i$ is deeply connected with the previously regarded Separator Problem. The idea behind the construction and the analysis of the algorithm is largely inspired by \cite{Approximatehierarchicalclusteringviasparsestcutandspreadingmetrics}. In order to tightly lower bound the value of the optimal solution, we split the cost of the optimal solution into levels, one for each $0\leq k < w\br
    T$, such that each level consists of a $w\br{T}/k$-separator of $T$.
    
    We start with some additional notation. By $L_{\OPT}\br{k}$ we will denote the set of all maximal subtrees of weight at most $k$ in $\OPT$. We call such set the $k$-th \textit{level} of $\OPT$. Observe that as two candidate subtrees $H_1, H_2$ may only have a common part when $H_1\subseteq H_2$ or $H_2\subseteq H_1$, by the minimality we have that $H_1 \cap H_2 =\emptyset$. We denote $S_{\OPT}\br{k}=V\br{T}-L_{\OPT}\br{k}$. These are the vertices belonging to the separator at the level $L_{\OPT}\br{k}$. 
    
            \begin{lemma}
                $\OPT=\sum_{k=0}^{w\br{T}-1}c\br{S_{\OPT}\br{k}}$
            \begin{proof}
                Consider any vertex $v$ and let $r$ be the weight of the subtree of candidates right before $v$ is queried. Then the contribution of $v$ to the LHS is $r\cdot c\br{v}$. On the other hand, for every $0\leq k<r$ we have that $v\in S_{\OPT}\br{k}$ so the contribution to the RHS is $r\cdot c\br{v}$ as well.
            \end{proof}
            \end{lemma}
            Using the above lemma one easily obtains the following lower bound on the cost of the optimal solution:
            $$
            2\cdot\OPT= 2\cdot\sum_{k=0}^{w\br{T}-1}c\br{S_{\OPT}\br{k}} \geq \sum_{k=0}^{w\br{T}}c\br{S_{\OPT}\br{\fl{k/2}}}
            $$
             
    Using the above lower bound on the value of $\OPT$ we will prove the main result of this section, namely:
    \begin{theorem}
        There exists a $4$-approximation algorithm for $T||V, w, c||\sum C_i$ running in time $O\br{n^2\br{\min\brc{c\br{T}, w\br{T}/\alpha}}^2}$ and a $\br{4+\epsilon}$-approximation algorithm running in time $O\br{n^4/\epsilon^2}$.
        \begin{proof}
            We describe how the obtain the $\br{4+\epsilon}$-approximation since the pseudopolynomial time algorithm can be formulated and analyzed similarly (using the exact algorithm for the weighted separator problem with $\alpha=2$).
            The procedure is as follows: 
            \input{pseudocodes/average_case_trees}
            \input{figures/average_case}
        
            Let $\mathcal{T}$ be a subtree for which the procedure was called. By the optimality of $S_{\mathcal{T}}$, we have that $c\br{S_{\mathcal{T}}}\leq c\br{S_{\OPT}\br{\fl{w\br{\mathcal{T}}/2}}\cap\mathcal{T}}$. Let $0<\beta<1$ be some constant. We have the following bound:
            $$
           \beta\cdot w\br{\mathcal{T}}\cdot c\br{S_{\OPT}\br{\fl{w\br{\mathcal{T}}/2}}\cap \mathcal{T}}
            \leq \sum_{k=\br{1-\beta}w\br{\mathcal{T}}+1}^{w\br{\mathcal{T}}}c\br{S_{\OPT}\br{\fl{k/2}}\cap \mathcal{T}}
            $$
            
             since as $k$ decreases, more vertices belong to the separator. 
            Using $\beta=\frac{1-\delta}{2}$ we have that the contribution of the decision tree $D_{\mathcal{T}}$ is therefore bounded by:
            \begin{align*}
                w\br{\mathcal{T}}\cdot c\br{S_{\mathcal{T}}}
                &\leq w\br{\mathcal{T}}\cdot c\br{S_{\OPT}\br{\fl{w\br{\mathcal{T}}/2}}\cap \mathcal{T}}\\
                &\leq \frac{2}{1-\delta}\cdot \sum_{k=\frac{1+\delta}{2}\cdot w\br{\mathcal{T}}+1}^{w\br{\mathcal{T}}}c\br{S_{\OPT}\br{\fl{k/2}}\cap \mathcal{T}}
            \end{align*}
            
            To bound the cost of the whole solution we will firstly show the following lemma which is necessary to proceed:
            \begin{lemma}
            $\sum_{\mathcal{T}}\sum_{k=w\br{\mathcal{T}}/2+1}^{w\br{\mathcal{T}}}c\br{S_{\OPT}\br{\fl{k/2}}\cap \mathcal{T}}\leq \sum_{k=0}^{w\br{T}}c\br{S_{\OPT}\br{\fl{k/2}}}$
            \begin{proof}
                Fix a value of $\mathcal{T}$ and $k$. Their contribution to the LHS is $c\br{S_{\OPT}\br{\fl{k/2}}\cap \mathcal{T}}$. Consider which subtrees for which the algorithm is called contribute such term to the LHS. As $S_{\mathcal{T}}$ is a weighted $\frac{2}{1+\delta}$-separator we have that $\mathcal{T}$ is the minimal candidate subtree such that $w\br{\mathcal{T}}\geq k\geq \frac{\br{1+\delta}w\br{\mathcal{T}}}{2}+1 >w\br{H}$ for every $H\in \mathcal{T}-S_{\mathcal{T}}$. This means that if for every $H\in \mathcal{T}-S_{\mathcal{T}}$: $w\br{H}<t$ then $\mathcal{T}$ contributes such a term. Using the fact that for every query, the set of possible responses consists of disjoint subtrees, we conclude for all $H_1, H_2\in \mathcal{T}-S_{\mathcal{T}}$ we have that $H_1\cap H_2=\emptyset$. Therefore also $\br{S_{\OPT}\br{\fl{k/2}}\cap H_1}\cap \br{S_{\OPT}\br{\fl{k/2}}\cap H_2=\emptyset}$ and the claim follows by summing over all $k$.
            \end{proof}
            \end{lemma}
        We are now ready to bound the cost of the solution. Let $D_T$ be the decision tree returned by the procedure. Using the fact that by definition $\frac{4}{1-\delta}=4+\epsilon$, we have:
        \begin{align*}
            c\br{D_T} &\leq \sum_{\mathcal{T}} w\br{\mathcal{T}}\cdot c\br{S_\mathcal{T}}\\
            &\leq \frac{2}{1-\delta}\cdot\sum_{\mathcal{T}}\sum_{k=\frac{1+\delta}{2}\cdot w\br{\mathcal{T}}+1}^{w\br{\mathcal{T}}}c\br{S_{\OPT}\br{\fl{k/2}}\cap \mathcal{T}}\\
            &\leq \frac{2}{1-\delta}\cdot\sum_{k=0}^{w\br{T}}c\br{S_{\OPT}\br{\fl{k/2}}}\leq \frac{4}{1-\delta}\cdot\OPT = \br{4+\epsilon}\cdot\OPT
    \end{align*}
        
    As $1/\delta=\frac{4+\epsilon}{\epsilon}=1+4/\epsilon$ and each $v\in V\br T$ belongs to the set $S_{\mathcal{T}}$ exactly once we have that the overall running time is at most $O\br{n^4/\epsilon^2}$ as required.
        \end{proof}
    \end{theorem}
\section{Arbitrary graphs}
% Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
% \subsection{Unitary costs, Worst case}
% Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
\subsection{Non-unitary costs, average case}
Below we show how to generalize the approach we used for $T||V,c,w||\sum C_i$. We follow a similar notation as before. By $L_{\OPT}\br{k}$ we will denote the set of all maximal connected subgraphs of weight at most $k$ in $\OPT$. We will call such subgraphs clusters and we call such set the $k$-th \textit{level} of $\OPT$. Observe that as two clusters $H_1, H_2$ may only have a common part when $H_1\subseteq H_2$ or $H_2\subseteq H_1$, by the minimality we have that $H_1 \cap H_2 =\emptyset$. We denote $S_{\OPT}\br{k}=V\br{G}-L_{\OPT}\br{k}$. These are the vertices belonging to the separator at the level $L_{\OPT}\br{k}$. 
However, in contrast to the analysis for $T||V,c,w||\sum C_i$, we will use a connection to a different problem. The (generalized) min-ratio vertex cut is as follows:

\begin{tcolorbox}[colback=white, title= Min-ratio vertex cut, fonttitle=\bfseries, breakable]
\paragraph{Input:} Graph $G=\br{V\br{G}, E\br{G}}$, the weight function $w:V\to \mathbb{N}^+$ and the cost function $c:V\to \mathbb{N}^+$.
\paragraph{Output:} A partition $\br{A,S,B}$ of $V\br{G}$ such that there is no $u\in A$ and $v\in B$ such that $uv\in E\br{G}$ which minimizes the ratio:
$$
\alpha_{c,w}\br{A,S,B}=\frac{c\br{S}}{w\br{A\cup S}\cdot w\br{B\cup S}}
$$
\end{tcolorbox}

Let $\OPT_{c,w}\br{G}$ denote the optimal value of such vertex cut.
We invoke the following result by \cite{Improvedapproximationalgorithmsvertexseparators} however we do not present their proof if this fact since it is quite involved. However we use the result below as a black box:
\begin{theorem}
    Given a graph $G=\br{V\br{G}, E\br{G}}$, the weight function $w:V\to \mathbb{N}^+$ and the cost function $c:V\to\mathbb{N}^+$, there exists a
polynomial-time algorithm which computes a partition $(A, S, B)$ for which:
$$
\alpha_{c,w}\br{A,S,B}=O\br{\sqrt{\log n
}}\cdot\OPT_{c,w}\br{G}
$$
\end{theorem}
We combine the latter with the following result which combined yield an $O\br{\sqrt{\log n
}}$-approximation algorithm for $G||V,c,w||\sum C_i$:
\begin{theorem}
    Let $f_n$ be the approximation ratio of any (polynomial time) algorithm  for the min-ratio vertex cut. Then, given a graph $G=\br{V\br{G}, E\br{G}}$, the weight function $w:V\to \mathbb{N}^+$, the cost function $c:V\to\mathbb{N}^+$ there exists an $O\br{f_n}$-approximation algorithm for $G||V,c,w||\sum C_i$ running in polynomial time.
    \begin{proof}
        \input{pseudocodes/average_case_graphs}
        As before we have the following property (we omit the proof as it is the same for case of arbitrary graphs):
        \begin{lemma} $\OPT=\sum_{k=0}^{w\br{G}-1}c\br{S_{\OPT}\br{k}}$
        \end{lemma}
        By which follows that:
            $$
            2\cdot\OPT= 2\cdot\sum_{k=0}^{w\br{G}-1}c\br{S_{\OPT}\br{k}} \geq \sum_{k=0}^{w\br{G}}c\br{S_{\OPT}\br{\fl{k/2}}}
            $$
            
        Let $\mathcal{G}$ be any cluster for which the procedure was called and let $r_{\mathcal{G}}=w\br{\mathcal{G}}$. Let $0<\beta<1$ be some constant. We have the following upper bound:
            $$
           \beta\cdot r_{\mathcal{G}}\cdot c\br{S_{\OPT}\br{\fl{r_{\mathcal{G}}/2}}\cap \mathcal{G}}
            \leq \sum_{k=\br{1-\beta}r_{\mathcal{G}}+1}^{r_{\mathcal{G}}}c\br{S_{\OPT}\br{\fl{k/2}}\cap \mathcal{G}}
            $$
        Denote by $H_1,\dots,H_p$ the connected components of $\mathcal{G}-S_{\OPT}\br{\fl{r_{\mathcal{G}}/2}\cap \mathcal{G}}$. Let $\gamma_j=w\br{H_j}/r_{\mathcal{G}}$ and $s=w\br{S_{\OPT}\br{\fl{r_{\mathcal{G}}/2}\cap \mathcal{G}}}$. We have the following lemma:
        \begin{lemma}
            Let $\lambda=6+2\sqrt{5}$. We can partition $H_1,\dots,H_p$ into two sets $A$ and $B$, with $a=w\br{A}$ and $b=w\br{B}$ such that $\br{a+s}\br{b+s}\geq r_{\mathcal{G}}^2/\lambda$.
            \begin{proof}
                There are two cases:
                \begin{enumerate}
                    \item $s\geq r_{\mathcal{G}}/\sqrt{\lambda}$. In this case we take arbitrary partition $A, B$ of $H_1,\dots,H_p$. We have:
                    $\br{a+s}\br{b+s}\geq s^2 = r_{\mathcal{G}}^2/\lambda $.
                    \item $s \leq r_{\mathcal{G}}/\sqrt{\lambda}$.
                Let $\gamma_A = \sum_{H_j\in A}\gamma_j$ and $\gamma_B = \sum_{H_j\in B}\gamma_j$. We have that $\gamma_A+\gamma_B\geq 1-\frac{1}{\sqrt{\lambda}}=\frac{\sqrt{\lambda}-1}{\sqrt{\lambda}}$. Let $A,B$ be the partition of $H_1,\dots,H_p$ into two subsets both of size at least $\br{\frac{\sqrt{\lambda}-1}{\sqrt{\lambda}}-\frac{1}{2}}\cdot r_{\mathcal{G}}$ (this is always possible as $\frac{\sqrt{\lambda}-1}{\sqrt{\lambda}} > \frac{1}{2}$ and for each $H_j$: $\gamma_j\leq 1/2$). We have:
                $$
                \br{a+s}\br{b+s}\geq ab \geq r_{\mathcal{G}}\cdot \br{\frac{\sqrt{\lambda}-1}{\sqrt{\lambda}}-\frac{1}{2}}\cdot\frac{r_{\mathcal{G}}}{2} = \frac{r_{\mathcal{G}}^2}{\lambda}
                $$
                (one can easily check that the equality is correct by substituting the value of $\lambda$). 
                \end{enumerate}
            \end{proof}
        \end{lemma}
        We therefore have the following upper bound on the value of the optimal min-ratio cut:
                $$\OPT_{c,w}\br{\mathcal{G}}\leq \frac{\lambda\cdot c\br{S_{\OPT}\br{\fl{r_{\mathcal{G}}/2}}\cap \mathcal{G}}}{r_{\mathcal{G}}^2}$$
        Let $\br{A_{\mathcal{G}},S_{\mathcal{G}}, B_{\mathcal{G}}}$ (with $a_{\mathcal{G}}=w\br{A_{\mathcal{G}}}$, $s_{\mathcal{G}}=w\br{S_{\mathcal{G}}}$, $b_{\mathcal{G}}=w\br{B_{\mathcal{G}}}$ and $a_{\mathcal{G}}\geq b_{\mathcal{G}}$) be the partition returned by the $f_n$-approximate algorithm so:
        $$
        \frac{c\br{S_{\mathcal{G}}}}{\br{a_{\mathcal{G}}+s_{\mathcal{G}}}\br{b_{\mathcal{G}}+s_{\mathcal{G}}}}\leq f_n \cdot \frac{\lambda} {r_{\mathcal{G}}^2}\cdot c\br{S_{\OPT}\br{\fl{r_{\mathcal{G}}/2}}\cap \mathcal{G}}
        $$
        Let $\beta=\br{b_{\mathcal{G}}+s_{\mathcal{G}}}/r_{\mathcal{G}}$. As $r_{\mathcal{G}}=a_{\mathcal{G}}+ s_{\mathcal{G}}+b_{\mathcal{G}}$ we have that $\br{1-\beta}r_{\mathcal{G}}+1 = a\br{\mathcal{G}}+1$ so we conclude that the contribution of the decision tree $D_{\mathcal{G}}$ is bounded by:
        \begin{align*}
        r_{\mathcal{G}}\cdot c\br{S_{\mathcal{G}}} &\leq \lambda \cdot f_n\cdot \frac{\br{a_{\mathcal{G}}+s_{\mathcal{G}}}\br{b_{\mathcal{G}}+s_{\mathcal{G}}}}{a_{\mathcal{G}}+s_{\mathcal{G}}+b_{\mathcal{G}}}\cdot c\br{S_{\OPT}\br{\fl{r_{\mathcal{G}}/2}}\cap \mathcal{G}}\\
        & \leq 
        \lambda \cdot f_n\cdot \br{b_{\mathcal{G}}+s_{\mathcal{G}}}\cdot c\br{S_{\OPT}\br{\fl{r_{\mathcal{G}}/2}}\cap \mathcal{G}} \\
        &\leq 
        \lambda \cdot f_n\cdot \sum_{k=a_{\mathcal{G}}+1}^{r_{\mathcal{G}}}c\br{S_{\OPT}\br{\fl{k/2}}\cap \mathcal{G}}
        \end{align*}

        As before, to bound the cost of the whole solution we will firstly show the following lemma. The argument is mostly the same, however there are few differences and we include it for completeness:
            \begin{lemma}
            $\sum_{\mathcal{G}}\sum_{k=a_{\mathcal{G}}+1}^{r_{\mathcal{G}}}c\br{S_{\OPT}\br{\fl{k/2}}\cap \mathcal{G}}\leq \sum_{k=0}^{w\br{G}}c\br{S_{\OPT}\br{\fl{k/2}}}$
            \begin{proof}
                Fix a value of $\mathcal{G}$ and $k$. Their contribution to the LHS is $c\br{S_{\OPT}\br{\fl{k/2}}\cap \mathcal{G}}$. Consider which clusters for which the algorithm is called contribute such term to the LHS. By definition of $S_{\mathcal{G}}$ we have that $\mathcal{G}$ is the minimal cluster such that $w\br{\mathcal{G}}\geq k\geq a_{\mathcal{G}}+1 >w\br{H}$ for every $H\in \mathcal{G}-S_{\mathcal{G}}$. This means that if for every $H\in \mathcal{G}-S_{\mathcal{G}}$: $w\br{H}<k$ then $\mathcal{G}$ contributes such a term. Using the fact that for every query, the set of possible responses consists of disjoint subgraphs, we conclude for all $H_1, H_2\in \mathcal{G}-S_{\mathcal{G}}$ we have that $H_1\cap H_2=\emptyset$. Therefore also $\br{S_{\OPT}\br{\fl{k/2}}\cap H_1}\cap \br{S_{\OPT}\br{\fl{k/2}}\cap H_2=\emptyset}$ and the claim follows by summing over all $k$.
            \end{proof}
            \end{lemma}
        We are now ready to bound the cost of the solution. Let $D_G$ be the decision tree returned by the procedure.
        \begin{align*}
            c\br{D_{G}}&\leq \sum_{\mathcal{G}}r_{\mathcal{G}}\cdot c\br{S_{\mathcal{G}}}\\
            &\leq \lambda \cdot f_n\cdot \sum_{\mathcal{G}}\sum_{k=a_{\mathcal{G}}+1}^{r_{\mathcal{G}}}c\br{S_{\OPT}\br{\fl{k/2}}\cap \mathcal{G}}\\
            &\leq
            \lambda \cdot f_n\cdot\sum_{k=0}^{w\br{G}}c\br{S_{\OPT}\br{\fl{k/2}}} \leq 2\cdot \lambda \cdot f_n\cdot \OPT\br{G} = \br{12+4\sqrt{5}}\cdot f_n \cdot \OPT\br{G}
        \end{align*}
        
    \end{proof}
    
\end{theorem}
% \section{Miscellaneous}
% Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
% \subsection{POSETS, worst case}
% Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
% \subsection{General set, uniform costs, average case, uniform weights}
% Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
% \subsection{Deadlines}
% Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.