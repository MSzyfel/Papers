\section{Problem statement}
\paragraph{Tree Search}
More formally, we model the search space as a tree $T$. The \textit{Vertex Tree Search Problem} is as follows: Among vertices of $T$ there is a hidden target vertex $x$ which is required to be located\footnote{It should be pointed out that the target vertex might not always be the same across multiple searches.}. During the search process, the searcher is allowed to perform queries, each about a chosen vertex $v\in V\br{T}$. In constant time the oracle responds whether the target is $v$ and if not, it identifies which connected component of $T-v$ contains $x$. Upon learning this information the searcher then iteratively picks the next vertex to query until the target is found. The goal is to create the optimal strategy for the searcher. 
One may also define an analogous process in which the queries concern edges. After a query to an edge $e$ the searcher learns which connected component of $T-e$ contains the target. We will call this problem the \textit{Edge Tree Search Problem}. For a visual example for both query models see Fig \ref{fig:sample_decision_trees_for_tree}.  
\input{figures/sample_decision_trees_for_tree}

When the input tree is a path both problems become the clasical binary search in the linearly ordered set.
We remark that for the vertex variant sometimes an alternative definition is provided. Upon query to $v$, if it is not the target, the response is an edge\footnote{Or equivaletly a vertex.} incident to $v$ which is the closest towards the target. This definition is equivalent as each component of $T-v$ has exactly one edge/vertex connecting it to $v$. A similar alternative/equivalent definition holds for the edge Tree Search Problem in which the response is the unique endpoint of $e$ laying closer to the target. The distinction between the two ways of defining the problem becomes significant when attempting to generalize it to arbitrary graphs.


\paragraph{Graph Search} In the following considerations we will be concerned with the generalization of the first definition of the Tree Search Problem. Given a graph $G$ the \textit{Vertex Graph Search Problem} is as follows: Among vertices of $G$ there exists a hidden target vertex $x$ which is required to be located. During the search process, the searcher is allowed to perform queries, each about a chosen vertex $v\in V\br{G}$. In constant time the oracle responds whether the target is $v$ and if not, it identifies which connected component of $G-v$ contains $x$. Again, the goal is to create the optimal strategy for the searcher. As before, a similar definition can be provided for the edge query model, which provides us with the \textit{Edge Graph Search Problem}. For a visual example of both query models see Figure \ref{fig:sample_decision_trees_for_graph}.

% In this generalized version of the problem, sometimes it might be the case that there is only one component $H\in G-v$. After a query to $v$, whenever $v$ is not the target the answer is always $H$. On the other hand, define the response to the query to $v$ as a vertex laying on the shortest path towards $x$. Whenever $v$ is not the target, there are exactly $\spr{N\br{v}}$ possible responses, Notice that in such case for each such response $u\in N(v)$ there is at least one vertex (namely the $u$ itself) for which the response is $u$ when it is the target. In fact the difference between the problems is also evident when considering their hardness. The "connected component" version of the problem is NP-hard while the "closest neighbor" version can be solved in quasipolynomial time. The choice of the generalization studied is a matter of taste, note that however the shortest distance query model may not behave deterministically. This is due to the fact that whenever there is more then one shortest path between $v$ and $x$ the answer to a query to $v$ may not always be the same. As this work deals only with the deterministic variants of the problem this choice arises naturally.

\input{figures/sample_decision_trees_for_graph}
% \paragraph{Poset Search and the Binary Identification Problem}
% A different generalization of the Edge Tree Search Problem is the \textit{Poset Search Problem}. In this problem we are given a partially ordered set (poset) $\mathcal{P}=\br{X, \preceq}$, where $X$ denotes the ground set of objects and $\preceq$ is a partial ordering of elements of $X$. In order for the problem to be properly defined we also require that $\mathcal{P}$ contains a unique maximum element $r$. Among $X$ there is a unique hidden target element $x$ which is required to be located. During the search process, the searcher is allowed to perform queries asking whether $x\preceq v$ for a chosen $v\in X$. Once again, the goal is to create the optimal strategy for the searcher. For a visual example see Figure \ref{fig:sample_decision_tree_for_poset}.

% \input{figures/sample_decision_trees_for_poset}

% The Poset Search Problem can be generalized even further by allowing each available query to be any partition of the search space. In the \textit{Binary Identification Problem} we are given a pair $\br{\mathcal{H}, \mathcal{Q}}$ where $\mathcal{H}$ is a set of hypotheses and $\mathcal{Q}$ is a set of queries. Each query $q = \brc{R_1, R_2,...R_k}$ is a partition of $\mathcal{H}$ (we require that $\bigcup_{R\in q}R=\mathcal{H}$ and for any $R_1,R_2\in q$: $R_1\cap R_2=\emptyset$). After performing a chosen query the searcher obtains information which $R\in q$ contains the hidden target. This process continuous iteratively until the target if found. For a visual example see Figure \ref{fig:sample_decision_tree_binary_identification_problem}. 

% In this broad sense this general model of searching can be interpreted using the information theory point of view. There exists a unique true hypotheses $h$ among the set $H=\brc{h_1,...,h_n}$ which the learner is trying to obtain. In order to do so, they iteratively collect small pieces of information which allow them to rule out certain hypothesis narrowing the search space. They do so until there is only one such hypothesis left. Analogously, the goal is to design a learning strategy which enables an efficient obtaining of this hidden hypothesis. 

% \input{figures/sample_decision_tree_binary_identification_problem}

\paragraph{Strategies, Decision Trees and their costs}
Notice, that while defining the searching the term strategy was never properly defined. The \textit{search strategy} is an adaptive algorithm which (in polynomial time) provides the searcher with the next query to perform (given the previous responses). A natural way to visualize such strategy is to see it as a decision tree. A \textit{decision tree} $D$ is a rooted tree in which each vertex represents a query and each edge represents a possible response. The search is conducted by choosing as the next query the root of $D$. After receiving the response (If the search is not terminated) the searcher moves along the edge $e=(r, r_e)$ incident to $r$ associated with the response. The process then recurses in $D_{r_e}$ until the target is found. It should be noted however, that this is far from the only viable way of encoding the search strategy. The choice of the data structure used is a matter of taste and often leads to simpler design and analysis of the algorithms.

In order to sensibly talk about the quality of such strategy we need to also measure its cost. The cost of locating a vertex $x$ using a strategy $A$ is the amount of queries required to be performed to find $x$ using $\mathcal{A}$. The two most intuitive ways to measure the overall cost of $\mathcal{A}$ are: 
\begin{itemize}
    \item The worst case search time which is maximum of costs of $\mathcal{A}$ over all vertices
    \item The average case which is the sum of costs of $\mathcal{A}$ over all vertices\footnote{The average of and the sum are equivalent up to a constant factor of $n$.}.
\end{itemize}

Even though similar, these two criterion often differ in their analysis and algorithms constructed for them usually exploit slightly different properties of the input. It is often the case that greedy heuristics perform much better when we measure the average case cost of the decision trees created by them. In contrast, in the worst case, often the best known solutions require some intricate dynamic programming procedure as an essential subroutine. Interestingly enough, it is not hard to show that given two decision trees: one with good performance in the average case and one with good performance in the worst case, a simple algorithm can be used to create new decision tree with fairly good performance in both metrics \cite{Tradingoff}.

\paragraph{Weights and Costs}
Above, we have made the assumption that performing each query costs us exactly the same. In real life applications it might not be a case. For example, determining the value of some complex comparison operation for two large objects may take a substantial amount of time. In such cases we associate with each query a cost function. To calculate the cost of finding $x$, instead of measuring the amount of queries, we measure the sum of their costs. The worst case and the average case criteria are then defined according to this new values. 

Additionally, when dealing with the average case version of the problem, one may consider a scenario in which certain vertices are searched for more often then the others. In general, we can associate with each vertex a probability/frequency of it being searched for which we will call its weight. In this case the average query time naturally becomes the weighted average according to this weight function \footnote{We assume that these cost and weight functions are known \textit{a-priori}.}.
