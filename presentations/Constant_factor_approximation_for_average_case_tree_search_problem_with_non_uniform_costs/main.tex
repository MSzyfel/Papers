\documentclass{beamer}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{chngcntr}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{indentfirst}
\usepackage{wrapfig}
\usepackage{adjustbox}
\usepackage{tikz}
\usepackage{textgreek}
\usepackage{float}
\usepackage{setspace}
\onehalfspacing
\usepackage{algorithmicx}
\usepackage{algorithm}
%\usepackage[noend, linesnumbered]{algpseudocode}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{geometry}
\usepackage{lscape}
\usepackage{appendix}
\usepackage{etoolbox}
\usepackage{tabularx}
\usepackage{array}
\usepackage{caption}
\usepackage{boxedminipage}
\usepackage[most]{tcolorbox}
\usepackage{xcolor}
\tcbuselibrary{breakable}
\usetikzlibrary{shadows}

\usetikzlibrary{decorations.pathreplacing,calligraphy}

\usepackage{csquotes} % Wymagane przez biblatex przy niektórych stylach

\usepackage[
  backend=biber,
  style=alphabetic,  % lub authoryear – zależnie od preferencji formatu
  sorting=nyt        % sortowanie: Name, Year, Title (alfabetycznie po autorze)
]{biblatex}

\renewcommand*{\bibfont}{\fontsize{6}{7}\selectfont}

\addbibresource{references.bib}


\newcommand{\br}[1]{\mathopen{}\left( #1 \right)}
\newcommand{\brc}[1]{\mathopen{}\left\{ #1 \right\}}
\newcommand{\spr}[1]{\mathopen{}\left| #1 \right|}
\newcommand{\fl}[1]{\mathopen{}\left\lfloor #1 \right\rfloor}
\newcommand{\cl}[1]{\mathopen{}\left\lceil #1 \right\rceil}
\newcommand{\angl}[1]{\mathopen{}\langle #1 \rangle}
\newcommand{\e}[1]{\exp\left\{ #1 \right\}}

\newcommand{\ecc}{\operatorname{ecc}}
\newcommand{\rad}{\operatorname{rad}}
\newcommand{\diam}{\operatorname{diam}}
\newcommand{\Rim}{\operatorname{Rim}}
\newcommand{\rim}{\operatorname{rim}}
\newcommand{\Anc}{\operatorname{Anc}}

\newcommand{\NPcomplete}{\textnormal{$\mathcal{NP}$-Complete}}
\newcommand{\NPhard}{\textnormal{$\mathcal{NP}$-Hard}}
\newcommand{\polyAPXcomplete}{\textnormal{Poly–$\mathcal{APX}$–Complete}}

\newcommand{\Cent}{\texttt{Cent}}
\newcommand{\APP}{\texttt{APP}}
\newcommand{\OPT}{\texttt{OPT}}
\newcommand{\COST}{\texttt{COST}}
\newcommand{\LB}{\mathcal{LB}}
\newcommand{\HB}{\mathcal{HB}}
\newcommand{\THB}{\mathcal{THB}}
\newcommand{\THH}{\texttt{TH}}

\newcommand{\argmin}{\mathopen{}\operatorname*{arg\,min}}
\newcommand{\argmax}{\mathopen{}\operatorname*{arg\,max}}


%Information to be included in the title page:
\title{Searching in Graphs
}
\author{Michał Szyfelbein}
\institute{Faculty of Electronics, Telecommunications and Informatics\\Gdańsk University of Technology, Poland}
\date{\today}

\begin{document}


\SetKwFunction{FSeparator}{Separator} 
\SetKwFunction{FSeparatorFPTAS}{SeparatorFPTAS}
\SetKwFunction{FDecisionTree}{DecisionTree}
\SetKwFunction{FAlgorithmMinCut}{AlgorithmMinCut}

\usetikzlibrary {graphs,graphdrawing} \usegdlibrary {trees, layered, force}

\frame{\titlepage}

\begin{frame}
\frametitle{Binary Search}
\textbf{Binary Search} – a classical strategy used to efficiently locate a hidden \textbf{target} element $x$ in a linearly ordered set $S$ using $O\br{\log n}$ comparison operations.
\pause
\input{figures/binary_search}

\end{frame}

\begin{frame}
\frametitle{Searching in Graphs}
\textbf{Easy to generalize to graphs:} 

A \textbf{query} to a vertex $v$ returns information whether $v$ is the target $x$, and if not, which connected component of $G-v$ contains $x$.
\pause
\input{figures/searching.tex}

\end{frame}
\begin{frame}\frametitle{Strategy of searching}

\textbf{We wish to find a strategy of searching.}
\input{figures/sample_decision_trees_for_graph.tex}
\end{frame}

\begin{frame}\frametitle{Additional parameters}
    \textbf{We introduce additional information about the input:}
    \begin{itemize}
        \item 
    To each vertex $v$ we assign an arbitrary \textbf{cost} $c\br{v}$, which denotes a cost of performing a query to $v$.
    \pause
    \item 
    Additionally, to each vertex $v$ we also assign an arbitrary \textbf{weight} $c\br{v}$, which denotes the importance of $v$.
    \pause
    \item For any $S\subseteq V\br{G}$, we denote $c\br{S}=\sum_{v\in S}c\br{v}$ and $w\br{S}=\sum_{v\in S}w\br{v}$.
    \end{itemize}

\end{frame}

\begin{frame}
\frametitle{Our setup}
\textbf{What is the best strategy of searching in a graph?}
\begin{tcolorbox}[colback=white, title=Graph Search Problem (GSP), fonttitle=\bfseries, breakable]
\textbf{Input:} Graph $G$, a query cost function $c\colon V\br{G}\to \mathbb{N}$ and a weight function $w\colon V\br{G}\to \mathbb{N}$.

\pause
\textbf{Output:} A decision tree $D$ minimizing the weighted average search cost: 
$$c_G\br{D} = \sum_{x\in V\br{G}}w\br{x}\cdot c\br{Q_G\br{D, x}}$$
where $Q_G\br{D,x}$ denotes the set of queries performed 
along the unique path in $D$ from the root $r\br{D}$ to $x$.
\end{tcolorbox}
\end{frame}

\begin{frame}\frametitle{Decision Tree}

\input{figures/sample_decision_trees_for_graph.tex}
\end{frame}

\begin{frame}{Why do we care?}
    \textbf{Useful in:}
    \begin{itemize}
        \item Automated bug detection in computer code,
        \item Hierarchical clustering of data.
    \end{itemize}
    \textbf{Related to:}
    \begin{itemize}
        \item Scheduling of parallel database join operations,
        \item Parallel Cholesky factorization of matrices,
        \item Parallel assembly of multi–part products from their components.
    \end{itemize}
\end{frame}

\begin{frame}{Why do we care?}
\textbf{Why our setup?:}
\begin{enumerate}
    \item \textbf{Average case} – it is natural to assume that the search strategies we design are intended to be used repeatedly. 
    \item \textbf{Weight function} – some vertices may serve 
as targets more frequently than the others. 
    \item \textbf{Query costs} – performing a query may require 
significant resources, such as time or money. 
\item \textbf{Have not yet been investigated.}
\end{enumerate} 
\end{frame}

\begin{frame}{Many names}
\begin{itemize}
    \item Binary Search \cite{Knuth1973,OnakParys2006GenOfBSSInTsAndFLikePosets,dereniowski2017ApproxSsForGeneralBSinWTs},
    \item Tree Search Problem \cite{Jacobs2010OnTheComplexSearchInTsAvg,Cicalese2016OnTSPwNonUniCost}, 
    \item Binary Identification Problem \cite{Cicalese2012BinIdentPForWTs}, 
    \item Ranking Colorings \cite{Lam1998ERankOfGsIsH,Dereniowski2009ERankOfWTs}, 
    \item Ordered Colorings \cite{KATCHALSKI1995141}, 
    \item Elimination Trees \cite{Pothen1988OptimalEliminationTrees}, 
    \item Hub Labeling \cite{Angelidakis2018ShortestPQ},
    \item Tree–Depth \cite{NESETRIL20061022},
    \item Partition Trees \cite{Hgemo2024TightAB},
    \item Hierarchical Clustering \cite{Acostfunctionforsimilaritybasedhierarchicalclustering,HCObjFsandAlgs,Approximatehierarchicalclusteringviasparsestcutandspreadingmetrics}, 
    \item Search Trees on Trees \cite{SplayTonT,Fast_app_centroid_trees}, 
    \item LIFO–Search \cite{GIANNOPOULOU20122089}. 
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{How to tackle the problem}
\textbf{Bad news:}
The Graph Search Problem is \textbf{NP–hard} even when restricted to bounded degree trees and bounded diameter trees. 
\pause

We want to find an algorithm providing a good \textbf{approximation} for the problem:
\begin{itemize}
    \item $\br{4+\epsilon}$–approximation for \textbf{trees}.
    \item $O\br{\sqrt{\log n}}$–approximation for \textbf{general graphs}.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Weighted $\alpha$–Separator Problem}
\begin{tcolorbox}[colback=white, title=Weighted $\alpha$–Separator Problem, fonttitle=\bfseries, breakable]
\textbf{Input:} Graph $G$, a cost function $c\colon V\to \mathbb{N}$, a weight function $w\colon V\to \mathbb{N}$ and a real number $\alpha$.

\pause
\textbf{Output:} A set $S\subseteq V\br{G}$ called \textbf{separator} such that for every $H\in G-S$, $w\br{H}\leq w\br{G}/\alpha$ and $c\br{S}$ is minimized.
\end{tcolorbox}

\end{frame}

\begin{frame}{Example of a separator}
    \input{figures/sample_separator}
\end{frame}

\begin{frame}{How to find the separator}
\textbf{Bad news again}: The Weighted $\alpha$–separator Problem is \textbf{NP–hard} as well.
\pause
But there exists a biciriteria \textbf{FPTAS} for trees:
\pause
\begin{theorem}
    Let $S$ be an optimal weighted $\alpha$–separator for $\br{T,c,w,\alpha}$. For any $\delta>0$ there exists an algorithm \FSeparatorFPTAS, which returns a separator $S'$, such that:
    \begin{enumerate}
        \pause
        \item $c\br{S'}\leq c\br{S}$.
        \pause
        \item $w\br{H}\leq \frac{\br{1+\delta}\cdot w\br{T}}{\alpha}$ for every $H\in T-S'$.
        \pause
        \item The algorithm runs in $O\br{n^3/\delta^2}$ time.
    \end{enumerate}
\end{theorem}

\end{frame}
\begin{frame}{Notation}
    \textbf{To connect searching and separating we need the following notation}:
    \begin{itemize}
        \item $\mathcal{R}_D\br{G}$ – 
the family of all candidate subsets of $D$ in $G$.
        \pause
        \item $D^*$ – optimal decision tree.
        \pause
        \item $\mathcal{L}_{k}^*$ – the $k$–th \textbf{level} of $\OPT\br{G}$: the subset of $\mathcal{R}_{D^*}\br{G}$
        consisting of all maximal elements $H$ of $\mathcal{R}_{D^*}\br{G}$ with $w\br{H} \leq k$.  
        \pause
        \item $S_{k}^* = V\br{G} - \mathcal{L}_{k}^*$ – vertices belonging to the separator at the level~$\mathcal{L}_{k}^*$. $S_{k}^*$ forms a weighted $w\br{G}/k$–separator of $G$.
    \end{itemize}

\end{frame}
\begin{frame}{Example of the connection}
\input{figures/connection.tex}
\end{frame}

\begin{frame}{Basic lemmas}
\begin{lemma}\label{contributionLemma}
Let $G_{D,v}$ be the candidate subgraph of $G$ in which 
$v$ is queried when using $D$. Then,
$
c_G\br{D} = \sum_{v \in V\br{G}} w\br{G_{D,v}} \cdot c\br{v}.
$
\end{lemma}
    \pause
\begin{lemma}
    $\OPT\br{G}=\sum_{k=0}^{w\br{G}-1}c\br{S_{k}^*}.$
    \pause
    \begin{proof}
        Consider any vertex $v$. For every $0\leq k<w\br{G_{D^*,v}}$, $v\notin \bigcup_{H\in \mathcal{L}_{k}^*}H$, so $v\in S_{k}^*$ and the contribution of $v$ to the cost is $w\br{G_{D^*,v}}\cdot c\br{v}$:
        $$\sum_{k=0}^{w\br{G}-1}c\br{S_{k}^*}=\sum_{v\in V\br{G}}\sum_{k=0}^{w\br{G_{D^*,v}}-1}c\br{v}=\OPT\br{G}.$$
    \end{proof}
\end{lemma}
\end{frame}

\begin{frame}{Example of the connection}
\input{figures/connection.tex}
\end{frame}


% \begin{frame}{Basic lemmas}
% \begin{lemma}\label{lb_opt}
%     $$
%     2\cdot\OPT\br{G}= 2\cdot\sum_{k=0}^{w\br{T}-1}c\br{S_{k}^*} \geq \sum_{k=0}^{w\br{T}}c\br{S_{\fl{k/2}}^*}.
%     $$
% \end{lemma}
%     \pause
% \begin{lemma}\label{splitting}
%     Let $\mathcal{G}$ be any subgraph of $G$ and $0\leq\beta\leq 1$. Then: 
%             $$
%            \beta\cdot w\br{\mathcal{G}}\cdot c\br{S_{\fl{w\br{\mathcal{G}}/2}}^*\cap \mathcal{G}}
%             \leq \sum_{k=\br{1-\beta}w\br{\mathcal{G}}+1}^{w\br{\mathcal{G}}}c\br{S_{\fl{k/2}}^*\cap \mathcal{G}}.
%             $$
% \end{lemma}
% \end{frame}



\begin{frame}{Searching in Trees}
We will iteratively use the \textbf{FPTAS} for the Weighted $\alpha$–separator problem to create an $\br{4+\epsilon}$–approximation algorithm for the Tree Search Problem:
\pause
\begin{theorem}
    For any $\epsilon>0$ there exists an $\br{4+\epsilon}$–approximation algorithm for the Tree Search Problem running in $O\br{n^4/\epsilon^2}$ time.
\end{theorem}
    
\end{frame}

\begin{frame}{The algorithm}
\textbf{proc} $\FDecisionTree\br{T,c,w,\epsilon}$:
\begin{enumerate}
    \item $S_T\gets\FSeparatorFPTAS\br{T, c, w, \alpha=2, \delta = \frac{\epsilon}{4+\epsilon}}$.
    \item $D_T\gets$ arbitrary partial decision tree for $T$, built from vertices of $S_T$.
    \item For each $H\in T-S_T$:
    \begin{enumerate}
        \item $D_H\gets\FDecisionTree\br{H,c,w,\epsilon}$.
        \item Hang $D_H$ in $D_T$ below the last query to $v\in N_T\br{H}$.
    \end{enumerate}
    \item Return $D_T$.
\end{enumerate}
\end{frame}

\begin{frame}{Structure of the solution}
\input{figures/algorithm}
\end{frame}

\begin{frame}{How does it work}
    \input{figures/sample_alg.tex}
\end{frame}

\begin{frame}{Sketch of the proof}
\begin{itemize}
    \item $\mathcal{T}$ – subtree of $T$ for which the procedure was called.
    \item Step 1. Bound the cost of \textbf{single} recurrence call:
    \pause
            \begin{align*}
                w\br{\mathcal{T}}&\cdot c\br{S_{\mathcal{T}}}
                \leq \frac{2}{1-\delta}\cdot \sum_{k=\frac{1+\delta}{2}\cdot w\br{\mathcal{T}}+1}^{w\br{\mathcal{T}}}c\br{S_{\fl{k/2}}^*\cap \mathcal{T}}.
            \end{align*}\pause
    \item Step 2. Bound the cost of the \textbf{whole} solution:
    \begin{align*}
            c_T\br{D} &\leq 
            \frac{2}{1-\delta}\cdot\sum_{\mathcal{T}}\sum_{k=\frac{1+\delta}{2}\cdot w\br{\mathcal{T}}+1}^{w\br{\mathcal{T}}}c\br{S_{\fl{k/2}}^*\cap \mathcal{T}}\\
            &\leq \frac{2}{1-\delta}\cdot\sum_{k=0}^{w\br{T}}c\br{S_{\fl{k/2}}^*}\leq  \br{4+\epsilon}\cdot\OPT\br{T}.
    \end{align*}
\end{itemize} 
\end{frame}



\begin{frame}{Min–Ratio Vertex Cut Problem}

\begin{tcolorbox}[colback=white, title= Min–Ratio Vertex Cut Problem, fonttitle=\bfseries, breakable]
\textbf{Input:} Graph $G=\br{V\br{G}, E\br{G}}$, the cost function $c\colon V\to \mathbb{N}$ and the weight function $w\colon V\to \mathbb{N}$.

\pause
\textbf{Output:} A partition $\br{A,S,B}$ of $V\br{G}$ called \textbf{vertex–cut}, such that there are no $u\in A$ and $v\in B$ for which $uv\in E\br{G}$, minimizing the ratio:
$$
\alpha_{c,w}\br{A,S,B}=\frac{c\br{S}}{w\br{A\cup S}\cdot w\br{B\cup S}}.
$$
\end{tcolorbox}
\end{frame}


\begin{frame}{Example of a vertex cut}
    \input{figures/sample_cut.tex}
\end{frame}

\begin{frame}{How to find the cut}
Min–Ratio Vertex Cut Problem is also \textbf{NP–hard}. However, we use the following result of \cite{Improvedapproximationalgorithmsvertexseparators}:
\begin{theorem}\label{approxmrvc}
    Given a graph $G=\br{V\br{G}, E\br{G}}$, the cost function $c:V\to\mathbb{N}$ and the weight function $w:V\to \mathbb{N}$, there exists a
polynomial–time algorithm, which computes a partition $(A, S, B)$, such that:
$$
\alpha_{c,w}\br{A,S,B}=O\br{\sqrt{\log n
}}\cdot\alpha_{c,w}\br{G}.
$$
\end{theorem}
\end{frame}


\begin{frame}{Searching in Graphs}
We will iteratively use the $f_n$–approximation algorithm for the Min–Ratio Vertex Cut Problem to create an $O\br{f_n}$–approximation algorithm for the Graph Search Problem:
\pause
\begin{theorem}
    Let $f_n$ be the approximation ratio of any polynomial time algorithm for the Min–Ratio Vertex Cut Problem. Then, there exists an $O\br{f_n}$–approximation algorithm for the Graph Search Problem, running in polynomial time.
\end{theorem}
    
\end{frame}

\begin{frame}{The algorithm}
\textbf{proc} $\FDecisionTree\br{T,c,w,\epsilon}$:
\begin{enumerate}
    \item $A_G,S_G, B_G\gets\FAlgorithmMinCut\br{G, c, w}$.
    \item $D_G\gets$ arbitrary partial decision tree for $G$, built from vertices of $S_G$.
    \item For each $H\in G-S_G$:
    \begin{enumerate}
        \item $D_H\gets \FDecisionTree\br{H, c, w}$.
        \item Hang $D_H$ in $D_G$ below the last query to $v\in N_G\br{H}$.
    \end{enumerate}
    \item Return $D_G$.
\end{enumerate}
\end{frame}

\begin{frame}{Sketch of the proof}

    \begin{itemize}
        \item $\mathcal{G}$ – any subgraph of $G$, for which the procedure was called.
    \item Step 1. Bound the cost of a \textbf{single} recurrence call:
    \begin{align*}
        w\br{\mathcal{G}}\cdot c\br{S_{\mathcal{G}}}\leq 
        11 \cdot f_n\cdot \sum_{k=w\br{A_{\mathcal{G}}}+1}^{w\br{\mathcal{G}}}c\br{S_{\fl{k/2}}^*\cap \mathcal{G}}.
        \end{align*}
    \pause
    \item Step 2. Bound the cost of the \textbf{whole} solution:
    \begin{align*}
            c_G\br{D}&\leq 11 \cdot f_n\cdot \sum_{\mathcal{G}}\sum_{k=w\br{A_{\mathcal{G}}}+1}^{w\br{\mathcal{G}}}c\br{S_{\fl{k/2}}^*\cap \mathcal{G}}
            \\&\leq 
            11 \cdot f_n\cdot\sum_{k=0}^{w\br{G}}c\br{S_{\fl{k/2}}^*} \leq  22 \cdot f_n \cdot \OPT\br{G}.
        \end{align*}
\end{itemize} 
\end{frame}


\begin{frame}
\centering
\huge
Thank you for your attention!

Questions?
\end{frame}

\begin{frame}[allowframebreaks]{Bibliography}
\printbibliography
\end{frame}
\end{document}